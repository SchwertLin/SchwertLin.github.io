<!DOCTYPE html><html lang="zh-CN"><head><meta charset="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta name="author" content="Schwertlilien"/><meta name="keyword"/><meta name="description" content="相当于现在的三个模态的数据：  高光谱：hdr，spe的数据 原始图片：.bmp 荧光值：表格中的item[Fluorescence intensity(A.U.)]  输出：Area&#x2F;Toxic content（Area公式可以计算得到Toxic content） 想要的结果分析： 除了这个训练得到的准确度之外， 最好还可以分析有关于不同的波长段对应的信息，哪个对于最终的回归结果更有影响（权重更">
<meta property="og:type" content="article">
<meta property="og:title" content="Fri Oct 17 2025 00:00:00 GMT+0800 (中國標準時間)">
<meta property="og:url" content="http://example.com/2025/10/17/2025-10-17/index.html">
<meta property="og:site_name" content="Schwertlilien">
<meta property="og:description" content="相当于现在的三个模态的数据：  高光谱：hdr，spe的数据 原始图片：.bmp 荧光值：表格中的item[Fluorescence intensity(A.U.)]  输出：Area&#x2F;Toxic content（Area公式可以计算得到Toxic content） 想要的结果分析： 除了这个训练得到的准确度之外， 最好还可以分析有关于不同的波长段对应的信息，哪个对于最终的回归结果更有影响（权重更">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2025-10-17T05:56:05.000Z">
<meta property="article:modified_time" content="2025-10-24T08:31:57.985Z">
<meta property="article:author" content="Schwertlilien">
<meta name="twitter:card" content="summary"><title>Fri Oct 17 2025 00:00:00 GMT+0800 (中國標準時間) - Schwertlilien - -----personal blog-----</title><link rel="shortcut icon" href="/img/site-icon.png">
<link rel="stylesheet" href="/css/style.css" id="dm-light">


<link rel="stylesheet" href="https://cdn.bootcdn.net/ajax/libs/font-awesome/6.4.2/css/all.min.css">

<script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script>
<meta name="generator" content="Hexo 7.3.0"></head><body><header><div class="top-nav" ondblclick="scrollToTop()"><div class="nav-info"><div class="nav-icon"><img id="nav-icon" src="/img/site-icon.png"/></div><div class="nav-title"><a id="nav-title" href="/" title="主页">Schwertlilien</a></div></div><div class="nav-ribbon"><div class="top-menu-expanded"><a class="top-menu-item" href="/archives"><span>归档</span></a><a class="top-menu-item" href="/categories"><span>分类</span></a><a class="top-menu-item" href="/tags"><span>标签</span></a><a class="top-menu-item" href="/about"><span>关于</span></a></div><div class="top-search" onclick="toggleSearchWindow()"><div id="top-search-btn" title="搜索"><i class="icon fa-solid fa-magnifying-glass"></i><span>搜索</span></div></div><div id="top-menu-btn" onclick="openTopMenu()" title="打开菜单"><i class="fa-solid fa-bars fa-lg"></i></div></div></div></header><div id="top-menu-hidden"><div class="menu-hidden-content"><div class="menu-hidden-nav"><a class="menu-hidden-item" href="/archives"><i class="fa-solid fa-box-archive fa-sm"></i><span>归档</span></a><a class="menu-hidden-item" href="/categories"><i class="fa-regular fa-folder-open fa-sm"></i><span>分类</span></a><a class="menu-hidden-item" href="/tags"><i class="fa-solid fa-tags fa-sm"></i><span>标签</span></a><a class="menu-hidden-item" href="/about"><i class="fa-solid fa-paw fa-sm"></i><span>关于</span></a></div></div><div class="menu-hidden-blank" onclick="closeTopMenu()"></div></div>
<div class="blog-info"><div class="blog-pic"><img id="blog-pic" src="/img/site-icon.png"/></div><div class="blog-title"><i class="fa-solid fa-paw fa-2xs fa-rotate-by"></i><span>Schwertlilien</span><i class="fa-solid fa-paw fa-2xs fa-rotate-by"></i></div><div class="blog-desc">As a recoder: notes and ideas.</div></div><div class="main"><div class="main-content"><article class="post"><div class="post-title"><h1><i class="fa-solid fa-paw"></i>Fri Oct 17 2025 00:00:00 GMT+0800 (中國標準時間)</h1></div><div class="post-info"><div class="post-info-first-line"><div class="post-date"><i class="icon fa-regular fa-calendar-plus" title="发布日期"></i><time class="publish-time">2025-10-17</time><i class="icon fa-regular fa-calendar-check" title="更新日期"></i><time class="update-time">2025-10-24</time></div>

</div><div class="post-info-second-line"><div class="post-copyright"><i class="icon fa-brands fa-creative-commons" title="版权声明"></i><span>版权声明: </span><a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-nd/4.0/deed.zh-hans" title="CC BY-NC-ND 4.0">署名-非商业性使用-禁止演绎 4.0</a></div>
<div class="post-word-count"><i class="icon fa-solid fa-pen-to-square"></i><span>全文约1.1W字</span></div><div class="pageview-post"><i class="icon fa-regular fa-eye"></i><span id="busuanzi_container_page_pv">阅读次数: <span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner"></i></span></span></div></div></div><div class="post-content"><p><strong>相当于现在的三个模态的数据</strong>：</p>
<ol>
<li>高光谱：hdr，spe的数据</li>
<li>原始图片：.bmp</li>
<li>荧光值：表格中的item[Fluorescence intensity(A.U.)]</li>
</ol>
<p><strong>输出</strong>：Area/Toxic content（Area公式可以计算得到Toxic content）</p>
<p><strong>想要的结果分析</strong>：</p>
<p>除了这个训练得到的准确度之外，</p>
<p>最好还可以分析有关于不同的波长段对应的信息，哪个对于最终的回归结果更有影响（权重更大）</p>
<p>以及以单图像进行输入，锁定目标位置后进行训练，得到的准确度的对比。</p>
<p>甲方要求：模型做一下优化，图像信息采集上能否也做优化</p>
<p>我在 <a href="vscode-file://vscode-app/private/var/folders/hh/64wwjv89403_wbnjbpxx0ymm0000gn/T/AppTranslocation/CD5B00AA-F75A-459C-A0C7-F7390FD34F02/d/Visual Studio Code.app/Contents/Resources/app/out/vs/code/electron-browser/workbench/workbench.html">multimodalDataset.py</a> 中添加了 <a href="vscode-file://vscode-app/private/var/folders/hh/64wwjv89403_wbnjbpxx0ymm0000gn/T/AppTranslocation/CD5B00AA-F75A-459C-A0C7-F7390FD34F02/d/Visual Studio Code.app/Contents/Resources/app/out/vs/code/electron-browser/workbench/workbench.html">prefilter_valid()</a>（找出 image+hdr+spe 都存在的样本）和 <a href="vscode-file://vscode-app/private/var/folders/hh/64wwjv89403_wbnjbpxx0ymm0000gn/T/AppTranslocation/CD5B00AA-F75A-459C-A0C7-F7390FD34F02/d/Visual Studio Code.app/Contents/Resources/app/out/vs/code/electron-browser/workbench/workbench.html">get_splits(val_ratio, test_ratio)</a>（返回 train/val/test 索引）；</p>
<ul>
<li>在本地运行结果：<ul>
<li>样本总数（Excel 中）= 1329</li>
<li>prefilter_valid 找到可用三模态样本数 = 1329（说明 <a href="vscode-file://vscode-app/private/var/folders/hh/64wwjv89403_wbnjbpxx0ymm0000gn/T/AppTranslocation/CD5B00AA-F75A-459C-A0C7-F7390FD34F02/d/Visual Studio Code.app/Contents/Resources/app/out/vs/code/electron-browser/workbench/workbench.html">_find_file</a> 现在能为所有样本定位到文件）</li>
<li>按默认 80/10/10 划分得到 sizes: 1065 / 132 / 132</li>
</ul>
</li>
<li>取了一个 DataLoader batch（batch_size=4）并用 <a href="vscode-file://vscode-app/private/var/folders/hh/64wwjv89403_wbnjbpxx0ymm0000gn/T/AppTranslocation/CD5B00AA-F75A-459C-A0C7-F7390FD34F02/d/Visual Studio Code.app/Contents/Resources/app/out/vs/code/electron-browser/workbench/workbench.html">collate_fn_mosi_regression</a> 验证：<ul>
<li>image: torch.Size([4, 3, 960, 960])</li>
<li>hyperspectral: torch.Size([4, 960, 960, 600])</li>
<li>fluorescence: torch.Size([4, 1])</li>
<li>labels: [4], mcs: [4], observeds: [4,3]</li>
</ul>
</li>
</ul>
<p>我现在需要利用一个具有三个模态的数据，来在I2MoE方法上进行训练测试。第一步是对数据进行编写相关的dataset：你现在先看一下这个表格/Volumes/Extreme Pro/001-实验数据-是这个/001-是这个/20251015-数据统计-是这个.xlsx中的数据，其中有荧光率的数据，以及对应的样品的name，荧光值：表格中的item[Fluorescence intensity(A.U.)]，表格中还有Area还有Toxic content这两个item，这两个item之间存在对应的关系，可以根据Area计算出Toxic content。所以我选定Area作为最终回归的任务的评估的ground truth（label）。此外，在/Volumes/Extreme Pro/001-实验数据-是这个/001-是这个/001-高光谱-是这个/4H/4-1/或事/Volumes/Extreme Pro/001-实验数据-是这个/001-是这个/001-高光谱-是这个/14h-2/14-33这种文件夹具有.bmp文件数据对应原始图片数据，以及两个.hdr和.spe文件对应原始测量 + 参考校准的高光谱和反射率的数据，我现在需要写出一个dataset能够对这三种数据进行处理，然后在<strong>getitem</strong>返回对应数据以及GT，然后便于后续的训练。</p>
<p>我现在需要你针对这个excel文件中Sample NameFluorescence intensity(A.U.)AreaToxic content的这个item，还有得到的/Volumes/Extreme Pro/001-实验数据-是这个/001-是这个/test/processed_npy/new_metadata.csv中对应的filename，把Fluorescence intensity(A.U.)这个item提取出来写一个csv，这个csv中要有filename，Fluorescence intensity(A.U.)，以及Sample Name。都要对应。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br><span class="line">429</span><br><span class="line">430</span><br><span class="line">431</span><br><span class="line">432</span><br><span class="line">433</span><br><span class="line">434</span><br><span class="line">435</span><br><span class="line">436</span><br><span class="line">437</span><br><span class="line">438</span><br><span class="line">439</span><br><span class="line">440</span><br><span class="line">441</span><br><span class="line">442</span><br><span class="line">443</span><br><span class="line">444</span><br><span class="line">445</span><br><span class="line">446</span><br><span class="line">447</span><br><span class="line">448</span><br><span class="line">449</span><br><span class="line">450</span><br><span class="line">451</span><br><span class="line">452</span><br><span class="line">453</span><br><span class="line">454</span><br><span class="line">455</span><br><span class="line">456</span><br><span class="line">457</span><br><span class="line">458</span><br><span class="line">459</span><br><span class="line">460</span><br><span class="line">461</span><br><span class="line">462</span><br><span class="line">463</span><br><span class="line">464</span><br><span class="line">465</span><br><span class="line">466</span><br><span class="line">467</span><br><span class="line">468</span><br><span class="line">469</span><br><span class="line">470</span><br><span class="line">471</span><br><span class="line">472</span><br><span class="line">473</span><br><span class="line">474</span><br><span class="line">475</span><br><span class="line">476</span><br><span class="line">477</span><br><span class="line">478</span><br><span class="line">479</span><br><span class="line">480</span><br><span class="line">481</span><br><span class="line">482</span><br><span class="line">483</span><br><span class="line">484</span><br><span class="line">485</span><br><span class="line">486</span><br><span class="line">487</span><br><span class="line">488</span><br><span class="line">489</span><br><span class="line">490</span><br><span class="line">491</span><br><span class="line">492</span><br><span class="line">493</span><br><span class="line">494</span><br><span class="line">495</span><br><span class="line">496</span><br><span class="line">497</span><br><span class="line">498</span><br><span class="line">499</span><br><span class="line">500</span><br><span class="line">501</span><br><span class="line">502</span><br><span class="line">503</span><br><span class="line">504</span><br><span class="line">505</span><br><span class="line">506</span><br><span class="line">507</span><br><span class="line">508</span><br><span class="line">509</span><br><span class="line">510</span><br><span class="line">511</span><br><span class="line">512</span><br><span class="line">513</span><br><span class="line">514</span><br><span class="line">515</span><br><span class="line">516</span><br><span class="line">517</span><br><span class="line">518</span><br><span class="line">519</span><br><span class="line">520</span><br><span class="line">521</span><br><span class="line">522</span><br><span class="line">523</span><br><span class="line">524</span><br><span class="line">525</span><br><span class="line">526</span><br><span class="line">527</span><br><span class="line">528</span><br><span class="line">529</span><br><span class="line">530</span><br><span class="line">531</span><br><span class="line">532</span><br><span class="line">533</span><br><span class="line">534</span><br><span class="line">535</span><br><span class="line">536</span><br><span class="line">537</span><br><span class="line">538</span><br><span class="line">539</span><br><span class="line">540</span><br><span class="line">541</span><br><span class="line">542</span><br><span class="line">543</span><br><span class="line">544</span><br><span class="line">545</span><br><span class="line">546</span><br><span class="line">547</span><br><span class="line">548</span><br><span class="line">549</span><br><span class="line">550</span><br><span class="line">551</span><br><span class="line">552</span><br><span class="line">553</span><br><span class="line">554</span><br><span class="line">555</span><br><span class="line">556</span><br><span class="line">557</span><br><span class="line">558</span><br><span class="line">559</span><br><span class="line">560</span><br><span class="line">561</span><br><span class="line">562</span><br><span class="line">563</span><br><span class="line">564</span><br><span class="line">565</span><br><span class="line">566</span><br><span class="line">567</span><br><span class="line">568</span><br><span class="line">569</span><br><span class="line">570</span><br><span class="line">571</span><br><span class="line">572</span><br><span class="line">573</span><br><span class="line">574</span><br><span class="line">575</span><br><span class="line">576</span><br><span class="line">577</span><br><span class="line">578</span><br><span class="line">579</span><br><span class="line">580</span><br><span class="line">581</span><br><span class="line">582</span><br><span class="line">583</span><br><span class="line">584</span><br><span class="line">585</span><br><span class="line">586</span><br><span class="line">587</span><br><span class="line">588</span><br><span class="line">589</span><br><span class="line">590</span><br><span class="line">591</span><br><span class="line">592</span><br><span class="line">593</span><br><span class="line">594</span><br><span class="line">595</span><br><span class="line">596</span><br><span class="line">597</span><br><span class="line">598</span><br><span class="line">599</span><br><span class="line">600</span><br><span class="line">601</span><br><span class="line">602</span><br><span class="line">603</span><br><span class="line">604</span><br><span class="line">605</span><br><span class="line">606</span><br><span class="line">607</span><br><span class="line">608</span><br><span class="line">609</span><br><span class="line">610</span><br><span class="line">611</span><br><span class="line">612</span><br><span class="line">613</span><br><span class="line">614</span><br><span class="line">615</span><br><span class="line">616</span><br><span class="line">617</span><br><span class="line">618</span><br><span class="line">619</span><br><span class="line">620</span><br><span class="line">621</span><br><span class="line">622</span><br><span class="line">623</span><br><span class="line">624</span><br><span class="line">625</span><br><span class="line">626</span><br><span class="line">627</span><br><span class="line">628</span><br><span class="line">629</span><br><span class="line">630</span><br><span class="line">631</span><br><span class="line">632</span><br><span class="line">633</span><br><span class="line">634</span><br><span class="line">635</span><br><span class="line">636</span><br><span class="line">637</span><br><span class="line">638</span><br><span class="line">639</span><br><span class="line">640</span><br><span class="line">641</span><br><span class="line">642</span><br><span class="line">643</span><br><span class="line">644</span><br><span class="line">645</span><br><span class="line">646</span><br><span class="line">647</span><br><span class="line">648</span><br><span class="line">649</span><br><span class="line">650</span><br><span class="line">651</span><br><span class="line">652</span><br><span class="line">653</span><br><span class="line">654</span><br><span class="line">655</span><br><span class="line">656</span><br><span class="line">657</span><br><span class="line">658</span><br><span class="line">659</span><br><span class="line">660</span><br><span class="line">661</span><br><span class="line">662</span><br><span class="line">663</span><br><span class="line">664</span><br><span class="line">665</span><br><span class="line">666</span><br><span class="line">667</span><br><span class="line">668</span><br><span class="line">669</span><br><span class="line">670</span><br><span class="line">671</span><br><span class="line">672</span><br><span class="line">673</span><br><span class="line">674</span><br><span class="line">675</span><br><span class="line">676</span><br><span class="line">677</span><br><span class="line">678</span><br><span class="line">679</span><br><span class="line">680</span><br><span class="line">681</span><br><span class="line">682</span><br><span class="line">683</span><br><span class="line">684</span><br><span class="line">685</span><br><span class="line">686</span><br><span class="line">687</span><br><span class="line">688</span><br><span class="line">689</span><br><span class="line">690</span><br><span class="line">691</span><br><span class="line">692</span><br><span class="line">693</span><br><span class="line">694</span><br><span class="line">695</span><br><span class="line">696</span><br><span class="line">697</span><br><span class="line">698</span><br><span class="line">699</span><br><span class="line">700</span><br><span class="line">701</span><br><span class="line">702</span><br><span class="line">703</span><br><span class="line">704</span><br><span class="line">705</span><br><span class="line">706</span><br><span class="line">707</span><br><span class="line">708</span><br><span class="line">709</span><br><span class="line">710</span><br><span class="line">711</span><br><span class="line">712</span><br><span class="line">713</span><br><span class="line">714</span><br><span class="line">715</span><br><span class="line">716</span><br><span class="line">717</span><br><span class="line">718</span><br><span class="line">719</span><br><span class="line">720</span><br><span class="line">721</span><br><span class="line">722</span><br><span class="line">723</span><br><span class="line">724</span><br><span class="line">725</span><br><span class="line">726</span><br><span class="line">727</span><br><span class="line">728</span><br><span class="line">729</span><br><span class="line">730</span><br><span class="line">731</span><br><span class="line">732</span><br><span class="line">733</span><br><span class="line">734</span><br><span class="line">735</span><br><span class="line">736</span><br><span class="line">737</span><br><span class="line">738</span><br><span class="line">739</span><br><span class="line">740</span><br><span class="line">741</span><br><span class="line">742</span><br><span class="line">743</span><br><span class="line">744</span><br><span class="line">745</span><br><span class="line">746</span><br><span class="line">747</span><br><span class="line">748</span><br><span class="line">749</span><br><span class="line">750</span><br><span class="line">751</span><br><span class="line">752</span><br><span class="line">753</span><br><span class="line">754</span><br><span class="line">755</span><br><span class="line">756</span><br><span class="line">757</span><br><span class="line">758</span><br><span class="line">759</span><br><span class="line">760</span><br><span class="line">761</span><br><span class="line">762</span><br><span class="line">763</span><br><span class="line">764</span><br><span class="line">765</span><br><span class="line">766</span><br><span class="line">767</span><br><span class="line">768</span><br><span class="line">769</span><br><span class="line">770</span><br><span class="line">771</span><br><span class="line">772</span><br><span class="line">773</span><br><span class="line">774</span><br><span class="line">775</span><br><span class="line">776</span><br><span class="line">777</span><br><span class="line">778</span><br><span class="line">779</span><br><span class="line">780</span><br><span class="line">781</span><br><span class="line">782</span><br><span class="line">783</span><br><span class="line">784</span><br><span class="line">785</span><br><span class="line">786</span><br><span class="line">787</span><br><span class="line">788</span><br><span class="line">789</span><br><span class="line">790</span><br><span class="line">791</span><br><span class="line">792</span><br><span class="line">793</span><br><span class="line">794</span><br><span class="line">795</span><br><span class="line">796</span><br><span class="line">797</span><br><span class="line">798</span><br><span class="line">799</span><br><span class="line">800</span><br><span class="line">801</span><br><span class="line">802</span><br><span class="line">803</span><br><span class="line">804</span><br><span class="line">805</span><br><span class="line">806</span><br><span class="line">807</span><br><span class="line">808</span><br><span class="line">809</span><br><span class="line">810</span><br><span class="line">811</span><br><span class="line">812</span><br><span class="line">813</span><br><span class="line">814</span><br><span class="line">815</span><br><span class="line">816</span><br><span class="line">817</span><br><span class="line">818</span><br><span class="line">819</span><br><span class="line">820</span><br><span class="line">821</span><br><span class="line">822</span><br><span class="line">823</span><br><span class="line">824</span><br><span class="line">825</span><br><span class="line">826</span><br><span class="line">827</span><br><span class="line">828</span><br><span class="line">829</span><br><span class="line">830</span><br><span class="line">831</span><br><span class="line">832</span><br><span class="line">833</span><br><span class="line">834</span><br><span class="line">835</span><br><span class="line">836</span><br><span class="line">837</span><br><span class="line">838</span><br><span class="line">839</span><br><span class="line">840</span><br><span class="line">841</span><br><span class="line">842</span><br><span class="line">843</span><br><span class="line">844</span><br><span class="line">845</span><br><span class="line">846</span><br><span class="line">847</span><br><span class="line">848</span><br><span class="line">849</span><br><span class="line">850</span><br><span class="line">851</span><br><span class="line">852</span><br><span class="line">853</span><br><span class="line">854</span><br><span class="line">855</span><br><span class="line">856</span><br><span class="line">857</span><br><span class="line">858</span><br><span class="line">859</span><br><span class="line">860</span><br><span class="line">861</span><br><span class="line">862</span><br><span class="line">863</span><br><span class="line">864</span><br><span class="line">865</span><br><span class="line">866</span><br><span class="line">867</span><br><span class="line">868</span><br><span class="line">869</span><br><span class="line">870</span><br><span class="line">871</span><br><span class="line">872</span><br><span class="line">873</span><br><span class="line">874</span><br><span class="line">875</span><br><span class="line">876</span><br><span class="line">877</span><br><span class="line">878</span><br><span class="line">879</span><br><span class="line">880</span><br><span class="line">881</span><br><span class="line">882</span><br><span class="line">883</span><br><span class="line">884</span><br><span class="line">885</span><br><span class="line">886</span><br><span class="line">887</span><br><span class="line">888</span><br><span class="line">889</span><br><span class="line">890</span><br><span class="line">891</span><br><span class="line">892</span><br><span class="line">893</span><br><span class="line">894</span><br><span class="line">895</span><br><span class="line">896</span><br><span class="line">897</span><br><span class="line">898</span><br><span class="line">899</span><br><span class="line">900</span><br><span class="line">901</span><br><span class="line">902</span><br><span class="line">903</span><br><span class="line">904</span><br><span class="line">905</span><br><span class="line">906</span><br><span class="line">907</span><br><span class="line">908</span><br><span class="line">909</span><br><span class="line">910</span><br><span class="line">911</span><br><span class="line">912</span><br><span class="line">913</span><br><span class="line">914</span><br><span class="line">915</span><br><span class="line">916</span><br><span class="line">917</span><br><span class="line">918</span><br><span class="line">919</span><br><span class="line">920</span><br><span class="line">921</span><br><span class="line">922</span><br><span class="line">923</span><br><span class="line">924</span><br><span class="line">925</span><br><span class="line">926</span><br><span class="line">927</span><br><span class="line">928</span><br><span class="line">929</span><br><span class="line">930</span><br><span class="line">931</span><br><span class="line">932</span><br><span class="line">933</span><br><span class="line">934</span><br><span class="line">935</span><br><span class="line">936</span><br><span class="line">937</span><br><span class="line">938</span><br><span class="line">939</span><br><span class="line">940</span><br><span class="line">941</span><br><span class="line">942</span><br><span class="line">943</span><br><span class="line">944</span><br><span class="line">945</span><br><span class="line">946</span><br><span class="line">947</span><br><span class="line">948</span><br><span class="line">949</span><br><span class="line">950</span><br><span class="line">951</span><br><span class="line">952</span><br><span class="line">953</span><br><span class="line">954</span><br><span class="line">955</span><br><span class="line">956</span><br><span class="line">957</span><br><span class="line">958</span><br><span class="line">959</span><br><span class="line">960</span><br><span class="line">961</span><br><span class="line">962</span><br><span class="line">963</span><br><span class="line">964</span><br><span class="line">965</span><br><span class="line">966</span><br><span class="line">967</span><br><span class="line">968</span><br><span class="line">969</span><br><span class="line">970</span><br><span class="line">971</span><br><span class="line">972</span><br><span class="line">973</span><br><span class="line">974</span><br><span class="line">975</span><br><span class="line">976</span><br><span class="line">977</span><br><span class="line">978</span><br><span class="line">979</span><br><span class="line">980</span><br><span class="line">981</span><br><span class="line">982</span><br><span class="line">983</span><br><span class="line">984</span><br><span class="line">985</span><br><span class="line">986</span><br><span class="line">987</span><br><span class="line">988</span><br><span class="line">989</span><br><span class="line">990</span><br><span class="line">991</span><br><span class="line">992</span><br><span class="line">993</span><br><span class="line">994</span><br><span class="line">995</span><br><span class="line">996</span><br><span class="line">997</span><br><span class="line">998</span><br><span class="line">999</span><br><span class="line">1000</span><br><span class="line">1001</span><br><span class="line">1002</span><br><span class="line">1003</span><br><span class="line">1004</span><br><span class="line">1005</span><br><span class="line">1006</span><br><span class="line">1007</span><br><span class="line">1008</span><br><span class="line">1009</span><br><span class="line">1010</span><br><span class="line">1011</span><br><span class="line">1012</span><br><span class="line">1013</span><br><span class="line">1014</span><br><span class="line">1015</span><br><span class="line">1016</span><br><span class="line">1017</span><br><span class="line">1018</span><br><span class="line">1019</span><br><span class="line">1020</span><br><span class="line">1021</span><br><span class="line">1022</span><br><span class="line">1023</span><br><span class="line">1024</span><br><span class="line">1025</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader, Dataset, Subset</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> models, transforms</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> MinMaxScaler, StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_absolute_error, r2_score, mean_squared_error</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"></span><br><span class="line">sns.set_theme(style=<span class="string">&quot;whitegrid&quot;</span>, font_scale=<span class="number">0.9</span>)</span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;DejaVu Sans&#x27;</span>]</span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_best_device</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Select the best available device: CUDA &gt; MPS (Apple Silicon) &gt; CPU.&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">            <span class="keyword">return</span> <span class="string">&#x27;cuda&#x27;</span></span><br><span class="line">    <span class="keyword">except</span> Exception:</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">hasattr</span>(torch.backends, <span class="string">&#x27;mps&#x27;</span>) <span class="keyword">and</span> torch.backends.mps.is_available():</span><br><span class="line">            <span class="keyword">return</span> <span class="string">&#x27;mps&#x27;</span></span><br><span class="line">    <span class="keyword">except</span> Exception:</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27;cpu&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">HyperspectralDataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, root_folder, metadata_file=<span class="string">&#x27;new_metadata.csv&#x27;</span>, transform=<span class="literal">None</span>, target_size=(<span class="params"><span class="number">256</span>, <span class="number">256</span></span>), scaler=<span class="literal">None</span>, feature_scaler=<span class="literal">None</span>, target_channels=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="variable language_">self</span>.root_folder = os.path.normpath(root_folder)</span><br><span class="line">        <span class="variable language_">self</span>.transform = transform</span><br><span class="line">        <span class="variable language_">self</span>.target_size = target_size</span><br><span class="line">        <span class="variable language_">self</span>.target_channels = target_channels</span><br><span class="line">        <span class="variable language_">self</span>.file_list = []</span><br><span class="line">        <span class="variable language_">self</span>.labels = []</span><br><span class="line">        <span class="variable language_">self</span>.raw_values = []</span><br><span class="line"></span><br><span class="line">        metadata_path = os.path.join(<span class="variable language_">self</span>.root_folder, metadata_file)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(metadata_path):</span><br><span class="line">            <span class="keyword">raise</span> FileNotFoundError(<span class="string">f&quot;Metadata file <span class="subst">&#123;metadata_path&#125;</span> not found&quot;</span>)</span><br><span class="line"></span><br><span class="line">        metadata = pd.read_csv(</span><br><span class="line">            metadata_path,</span><br><span class="line">            dtype=&#123;<span class="string">&#x27;toxin_value&#x27;</span>: <span class="built_in">float</span>, <span class="string">&#x27;Value_Raw&#x27;</span>: <span class="built_in">float</span>&#125;,</span><br><span class="line">            encoding=<span class="string">&#x27;utf-8-sig&#x27;</span></span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Filter out abnormal data with toxin_value &gt; 20</span></span><br><span class="line">        valid_metadata = metadata[metadata[<span class="string">&#x27;toxin_value&#x27;</span>] &lt;= <span class="number">20</span>]</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Found <span class="subst">&#123;<span class="built_in">len</span>(valid_metadata)&#125;</span> valid samples (toxin_value ≤ 20)&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Count filtered abnormal data</span></span><br><span class="line">        invalid_count = <span class="built_in">len</span>(metadata) - <span class="built_in">len</span>(valid_metadata)</span><br><span class="line">        <span class="keyword">if</span> invalid_count &gt; <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;⚠️ Warning: Filtered <span class="subst">&#123;invalid_count&#125;</span> abnormal samples (toxin_value &gt; 20)&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Process valid data</span></span><br><span class="line">        <span class="comment"># Prefer using npy_filename (相对于 root_folder 的 .npy 路径)</span></span><br><span class="line">        has_npy_col = <span class="string">&#x27;npy_filename&#x27;</span> <span class="keyword">in</span> valid_metadata.columns</span><br><span class="line">        <span class="keyword">for</span> idx, row <span class="keyword">in</span> valid_metadata.iterrows():</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                <span class="comment"># choose path source</span></span><br><span class="line">                <span class="keyword">if</span> has_npy_col <span class="keyword">and</span> <span class="built_in">isinstance</span>(row[<span class="string">&#x27;npy_filename&#x27;</span>], <span class="built_in">str</span>) <span class="keyword">and</span> <span class="built_in">len</span>(row[<span class="string">&#x27;npy_filename&#x27;</span>].strip()) &gt; <span class="number">0</span>:</span><br><span class="line">                    rel_path = row[<span class="string">&#x27;npy_filename&#x27;</span>].strip()</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="comment"># fallback: use &#x27;filename&#x27; only if it points to a .npy (relative or absolute)</span></span><br><span class="line">                    rel_path = <span class="built_in">str</span>(row[<span class="string">&#x27;filename&#x27;</span>]).strip()</span><br><span class="line">                <span class="comment"># resolve to absolute path</span></span><br><span class="line">                <span class="keyword">if</span> os.path.isabs(rel_path):</span><br><span class="line">                    file_path = os.path.normpath(rel_path)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    file_path = os.path.normpath(os.path.join(<span class="variable language_">self</span>.root_folder, rel_path))</span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">not</span> os.path.isfile(file_path):</span><br><span class="line">                    <span class="built_in">print</span>(<span class="string">f&quot;Warning: File <span class="subst">&#123;file_path&#125;</span> not found, skipping&quot;</span>)</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                toxin_value = <span class="built_in">float</span>(row[<span class="string">&#x27;toxin_value&#x27;</span>])</span><br><span class="line">                raw_value = <span class="built_in">float</span>(row[<span class="string">&#x27;Value_Raw&#x27;</span>])</span><br><span class="line">                </span><br><span class="line">                <span class="variable language_">self</span>.file_list.append(file_path)</span><br><span class="line">                <span class="variable language_">self</span>.labels.append(toxin_value)</span><br><span class="line">                <span class="variable language_">self</span>.raw_values.append(raw_value)</span><br><span class="line">            <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;Error processing file <span class="subst">&#123;file_path&#125;</span>: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> <span class="variable language_">self</span>.file_list:</span><br><span class="line">            <span class="keyword">raise</span> RuntimeError(<span class="string">&quot;No valid data found&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Successfully loaded <span class="subst">&#123;<span class="built_in">len</span>(self.file_list)&#125;</span> samples&quot;</span>)</span><br><span class="line">        <span class="variable language_">self</span>.labels = np.array(<span class="variable language_">self</span>.labels).reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        <span class="variable language_">self</span>.raw_values = np.array(<span class="variable language_">self</span>.raw_values).reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Normalize labels to [0, 1] range using MinMaxScaler</span></span><br><span class="line">        <span class="keyword">if</span> scaler:</span><br><span class="line">            <span class="variable language_">self</span>.labels = scaler.transform(<span class="variable language_">self</span>.labels)</span><br><span class="line">        <span class="variable language_">self</span>.labels = <span class="variable language_">self</span>.labels.flatten()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Normalize features using StandardScaler</span></span><br><span class="line">        <span class="keyword">if</span> feature_scaler:</span><br><span class="line">            <span class="variable language_">self</span>.raw_values = feature_scaler.transform(<span class="variable language_">self</span>.raw_values)</span><br><span class="line">        <span class="variable language_">self</span>.raw_values = <span class="variable language_">self</span>.raw_values.flatten()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Check sample data shape</span></span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.file_list:</span><br><span class="line">            sample_data = np.load(<span class="variable language_">self</span>.file_list[<span class="number">0</span>])</span><br><span class="line">            <span class="keyword">if</span> sample_data.shape[:<span class="number">2</span>] != <span class="variable language_">self</span>.target_size:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;⚠️ Warning: Input size <span class="subst">&#123;sample_data.shape[:<span class="number">2</span>]&#125;</span> does not match target size <span class="subst">&#123;self.target_size&#125;</span>, resizing automatically&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(<span class="variable language_">self</span>.file_list)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, idx</span>):</span><br><span class="line">        file_path = <span class="variable language_">self</span>.file_list[idx]</span><br><span class="line">        data = <span class="literal">None</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="comment"># Try to load, handling corrupted files</span></span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                data = np.load(file_path)</span><br><span class="line">            <span class="keyword">except</span> ValueError <span class="keyword">as</span> ve:</span><br><span class="line">                <span class="keyword">if</span> <span class="string">&quot;mmap length is greater than file size&quot;</span> <span class="keyword">in</span> <span class="built_in">str</span>(ve) <span class="keyword">or</span> <span class="string">&quot;cannot reshape&quot;</span> <span class="keyword">in</span> <span class="built_in">str</span>(ve):</span><br><span class="line">                    <span class="comment"># File has shape mismatch, try to load raw data and reshape correctly</span></span><br><span class="line">                    <span class="built_in">print</span>(<span class="string">f&quot;Warning: <span class="subst">&#123;file_path&#125;</span> has shape mismatch, attempting manual load&quot;</span>)</span><br><span class="line">                    <span class="keyword">with</span> <span class="built_in">open</span>(file_path, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">                        version = np.lib.<span class="built_in">format</span>.read_magic(f)</span><br><span class="line">                        shape, fortran_order, dtype = np.lib.<span class="built_in">format</span>.read_array_header_1_0(f)</span><br><span class="line">                        <span class="comment"># Read only available data</span></span><br><span class="line">                        remaining_data = f.read()</span><br><span class="line">                        expected_bytes = np.prod(shape) * np.dtype(dtype).itemsize</span><br><span class="line">                        actual_bytes = <span class="built_in">len</span>(remaining_data)</span><br><span class="line">                        <span class="built_in">print</span>(<span class="string">f&quot;Header shape: <span class="subst">&#123;shape&#125;</span>, expected <span class="subst">&#123;expected_bytes&#125;</span> bytes, got <span class="subst">&#123;actual_bytes&#125;</span> bytes&quot;</span>)</span><br><span class="line">                        </span><br><span class="line">                        <span class="keyword">if</span> actual_bytes &gt; <span class="number">0</span>:</span><br><span class="line">                            <span class="comment"># Load what we can</span></span><br><span class="line">                            elements = actual_bytes // np.dtype(dtype).itemsize</span><br><span class="line">                            flat_data = np.frombuffer(remaining_data[:elements * np.dtype(dtype).itemsize], dtype=dtype)</span><br><span class="line">                            </span><br><span class="line">                            <span class="comment"># Try to infer actual dimensions from file size</span></span><br><span class="line">                            <span class="comment"># Common patterns: (957,960,300), (960,960,300), etc.</span></span><br><span class="line">                            <span class="keyword">if</span> <span class="built_in">len</span>(shape) == <span class="number">3</span>:</span><br><span class="line">                                h_expected, w_expected, c_expected = shape</span><br><span class="line">                                <span class="comment"># Calculate what the actual height should be</span></span><br><span class="line">                                actual_h = elements // (w_expected * c_expected)</span><br><span class="line">                                <span class="keyword">if</span> actual_h * w_expected * c_expected == elements:</span><br><span class="line">                                    <span class="built_in">print</span>(<span class="string">f&quot;Reshaping to (<span class="subst">&#123;actual_h&#125;</span>, <span class="subst">&#123;w_expected&#125;</span>, <span class="subst">&#123;c_expected&#125;</span>) instead of <span class="subst">&#123;shape&#125;</span>&quot;</span>)</span><br><span class="line">                                    data = flat_data.reshape(actual_h, w_expected, c_expected)</span><br><span class="line">                                <span class="keyword">else</span>:</span><br><span class="line">                                    <span class="comment"># Try other common dimensions</span></span><br><span class="line">                                    <span class="keyword">for</span> c <span class="keyword">in</span> [<span class="number">300</span>, <span class="number">600</span>, <span class="number">900</span>]:</span><br><span class="line">                                        <span class="keyword">for</span> w <span class="keyword">in</span> [<span class="number">960</span>, <span class="number">957</span>, <span class="number">950</span>]:</span><br><span class="line">                                            h = elements // (w * c)</span><br><span class="line">                                            <span class="keyword">if</span> h * w * c == elements <span class="keyword">and</span> h &gt; <span class="number">0</span>:</span><br><span class="line">                                                <span class="built_in">print</span>(<span class="string">f&quot;Reshaping to (<span class="subst">&#123;h&#125;</span>, <span class="subst">&#123;w&#125;</span>, <span class="subst">&#123;c&#125;</span>)&quot;</span>)</span><br><span class="line">                                                data = flat_data.reshape(h, w, c)</span><br><span class="line">                                                <span class="keyword">break</span></span><br><span class="line">                                        <span class="keyword">if</span> data <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                                            <span class="keyword">break</span></span><br><span class="line">                            </span><br><span class="line">                            <span class="comment"># If still no success, try fallback reshape</span></span><br><span class="line">                            <span class="keyword">if</span> data <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">and</span> elements &gt;= <span class="number">256</span> * <span class="number">256</span>:</span><br><span class="line">                                <span class="comment"># Find best square dimensions</span></span><br><span class="line">                                sqrt_elem = <span class="built_in">int</span>(np.sqrt(elements))</span><br><span class="line">                                <span class="keyword">while</span> sqrt_elem &gt; <span class="number">0</span> <span class="keyword">and</span> elements % sqrt_elem != <span class="number">0</span>:</span><br><span class="line">                                    sqrt_elem -= <span class="number">1</span></span><br><span class="line">                                <span class="keyword">if</span> sqrt_elem &gt; <span class="number">0</span>:</span><br><span class="line">                                    height = sqrt_elem</span><br><span class="line">                                    width = elements // sqrt_elem</span><br><span class="line">                                    data = flat_data[:height*width].reshape(height, width, <span class="number">1</span>)</span><br><span class="line">                                <span class="keyword">else</span>:</span><br><span class="line">                                    <span class="comment"># Fallback to small square</span></span><br><span class="line">                                    side = <span class="built_in">int</span>(np.sqrt(elements))</span><br><span class="line">                                    data = flat_data[:side*side].reshape(side, side, <span class="number">1</span>)</span><br><span class="line">                            <span class="keyword">elif</span> data <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">                                <span class="comment"># Very small data, create minimal image</span></span><br><span class="line">                                data = np.zeros((<span class="number">64</span>, <span class="number">64</span>, <span class="number">1</span>), dtype=np.float32)</span><br><span class="line">                        <span class="keyword">else</span>:</span><br><span class="line">                            <span class="keyword">raise</span> ValueError(<span class="string">&quot;No data to load&quot;</span>)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="keyword">raise</span> ve</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># Handle potential shape mismatches with robust reshaping</span></span><br><span class="line">            <span class="keyword">if</span> data.ndim == <span class="number">1</span>:</span><br><span class="line">                <span class="comment"># Try to infer shape from file size - assume square spatial dimensions</span></span><br><span class="line">                total_size = data.size</span><br><span class="line">                <span class="comment"># Try common channel counts first</span></span><br><span class="line">                <span class="keyword">for</span> channels <span class="keyword">in</span> [<span class="number">300</span>, <span class="number">600</span>, <span class="number">900</span>, <span class="number">1200</span>]:</span><br><span class="line">                    spatial_size = total_size // channels</span><br><span class="line">                    spatial_dim = <span class="built_in">int</span>(np.sqrt(spatial_size))</span><br><span class="line">                    <span class="keyword">if</span> spatial_dim * spatial_dim * channels == total_size:</span><br><span class="line">                        data = data.reshape(spatial_dim, spatial_dim, channels)</span><br><span class="line">                        <span class="keyword">break</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="comment"># Fallback: treat as single channel</span></span><br><span class="line">                    spatial_dim = <span class="built_in">int</span>(np.sqrt(total_size))</span><br><span class="line">                    <span class="keyword">if</span> spatial_dim * spatial_dim == total_size:</span><br><span class="line">                        data = data.reshape(spatial_dim, spatial_dim, <span class="number">1</span>)</span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        <span class="comment"># Force to a reasonable shape</span></span><br><span class="line">                        target_size = <span class="built_in">min</span>(<span class="number">256</span>, spatial_dim)</span><br><span class="line">                        data = data[:target_size*target_size].reshape(target_size, target_size, <span class="number">1</span>)</span><br><span class="line">            <span class="keyword">elif</span> data.ndim == <span class="number">2</span>:</span><br><span class="line">                <span class="comment"># Add channel dimension</span></span><br><span class="line">                data = data[:, :, np.newaxis]</span><br><span class="line">            <span class="comment"># data should now be (H, W, C)</span></span><br><span class="line">            </span><br><span class="line">            data = <span class="variable language_">self</span>.resize_data(data)</span><br><span class="line">            data = torch.tensor(data, dtype=torch.float32).permute(<span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>).contiguous()</span><br><span class="line">            <span class="comment"># Ensure consistent channel size across samples</span></span><br><span class="line">            <span class="keyword">if</span> <span class="variable language_">self</span>.target_channels <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                c, h, w = data.shape</span><br><span class="line">                <span class="keyword">if</span> c &gt; <span class="variable language_">self</span>.target_channels:</span><br><span class="line">                    data = data[:<span class="variable language_">self</span>.target_channels, :, :].contiguous()</span><br><span class="line">                <span class="keyword">elif</span> c &lt; <span class="variable language_">self</span>.target_channels:</span><br><span class="line">                    pad = torch.zeros(<span class="variable language_">self</span>.target_channels - c, h, w, dtype=data.dtype)</span><br><span class="line">                    data = torch.cat([data, pad], dim=<span class="number">0</span>).contiguous()</span><br><span class="line">            <span class="keyword">if</span> <span class="variable language_">self</span>.transform:</span><br><span class="line">                data = <span class="variable language_">self</span>.transform(data)</span><br><span class="line">            label = torch.tensor(<span class="variable language_">self</span>.labels[idx], dtype=torch.float32)</span><br><span class="line">            raw_value = torch.tensor(<span class="variable language_">self</span>.raw_values[idx], dtype=torch.float32)</span><br><span class="line">            <span class="keyword">return</span> data, label, raw_value</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;Error loading <span class="subst">&#123;file_path&#125;</span>: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">            <span class="keyword">if</span> data <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;Array shape: <span class="subst">&#123;data.shape&#125;</span>, size: <span class="subst">&#123;data.size&#125;</span>&quot;</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;Failed to load array&quot;</span>)</span><br><span class="line">            <span class="comment"># Return a dummy tensor to avoid breaking the DataLoader</span></span><br><span class="line">            dummy_data = torch.zeros(<span class="variable language_">self</span>.target_channels <span class="keyword">or</span> <span class="number">300</span>, *<span class="variable language_">self</span>.target_size, dtype=torch.float32)</span><br><span class="line">            dummy_label = torch.tensor(<span class="number">0.0</span>, dtype=torch.float32)</span><br><span class="line">            dummy_raw = torch.tensor(<span class="number">0.0</span>, dtype=torch.float32)</span><br><span class="line">            <span class="keyword">return</span> dummy_data, dummy_label, dummy_raw</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">resize_data</span>(<span class="params">self, data</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Resize images using PyTorch&#x27;s efficient interpolation&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> data.ndim == <span class="number">2</span>:</span><br><span class="line">            data = data[:, :, np.newaxis]</span><br><span class="line">        data_tensor = torch.tensor(data, dtype=torch.float32).permute(<span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">        resized = F.interpolate(</span><br><span class="line">            data_tensor.unsqueeze(<span class="number">0</span>),</span><br><span class="line">            size=<span class="variable language_">self</span>.target_size,</span><br><span class="line">            mode=<span class="string">&#x27;bilinear&#x27;</span>,</span><br><span class="line">            align_corners=<span class="literal">False</span></span><br><span class="line">        )</span><br><span class="line">        <span class="comment"># Return a fresh, contiguous numpy array to avoid non-resizable storage issues in DataLoader</span></span><br><span class="line">        <span class="keyword">return</span> resized.squeeze(<span class="number">0</span>).permute(<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>).contiguous().cpu().numpy().copy()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">compute_or_load_stats</span>(<span class="params">dataset, cache_path=<span class="string">&#x27;stats.json&#x27;</span>, label_scaler=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Compute or load statistics including normalization parameters for targets&quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># Check if cache exists</span></span><br><span class="line">    <span class="keyword">if</span> os.path.exists(cache_path):</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(cache_path, <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            stats = json.load(f)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Loaded statistics from <span class="subst">&#123;cache_path&#125;</span>&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Check if cache contains toxin normalization parameters</span></span><br><span class="line">        has_toxin_params = <span class="string">&#x27;toxin_min&#x27;</span> <span class="keyword">in</span> stats <span class="keyword">and</span> <span class="string">&#x27;toxin_max&#x27;</span> <span class="keyword">in</span> stats</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> has_toxin_params:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Cache contains toxin normalization parameters&quot;</span>)</span><br><span class="line">            <span class="keyword">return</span> (</span><br><span class="line">                stats[<span class="string">&#x27;mean&#x27;</span>], </span><br><span class="line">                stats[<span class="string">&#x27;std&#x27;</span>], </span><br><span class="line">                stats[<span class="string">&#x27;toxin_min&#x27;</span>], </span><br><span class="line">                stats[<span class="string">&#x27;toxin_max&#x27;</span>]</span><br><span class="line">            )</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;⚠️ Warning: Cache does not contain toxin normalization parameters, will recompute statistics&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Recompute statistics</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Computing dataset statistics (mean and std)... This may take some time&quot;</span>)</span><br><span class="line">    <span class="comment"># Use single worker for stability on macOS</span></span><br><span class="line">    loader = DataLoader(dataset, batch_size=<span class="number">16</span>, shuffle=<span class="literal">False</span>, num_workers=<span class="number">0</span>, pin_memory=<span class="literal">False</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        channels = dataset[<span class="number">0</span>][<span class="number">0</span>].shape[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">except</span> IndexError:</span><br><span class="line">        <span class="keyword">raise</span> RuntimeError(<span class="string">&quot;Dataset is empty, cannot compute statistics&quot;</span>)</span><br><span class="line"></span><br><span class="line">    total = torch.zeros(channels)</span><br><span class="line">    total_sq = torch.zeros(channels)</span><br><span class="line">    num_pixels = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> data, _, _ <span class="keyword">in</span> tqdm(loader, desc=<span class="string">&quot;Computing statistics&quot;</span>):</span><br><span class="line">        data = data.view(data.size(<span class="number">0</span>), channels, -<span class="number">1</span>)</span><br><span class="line">        total += data.<span class="built_in">sum</span>(dim=[<span class="number">0</span>, <span class="number">2</span>])</span><br><span class="line">        total_sq += (data ** <span class="number">2</span>).<span class="built_in">sum</span>(dim=[<span class="number">0</span>, <span class="number">2</span>])</span><br><span class="line">        num_pixels += data.shape[<span class="number">0</span>] * data.shape[<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">    mean = (total / num_pixels).tolist()</span><br><span class="line">    std = ((total_sq / num_pixels - torch.tensor(mean) ** <span class="number">2</span>) ** <span class="number">0.5</span>).tolist()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Save target normalization parameters (min, max)</span></span><br><span class="line">    toxin_min = <span class="built_in">float</span>(label_scaler.data_min_[<span class="number">0</span>]) <span class="keyword">if</span> label_scaler <span class="keyword">else</span> <span class="number">0.0</span></span><br><span class="line">    toxin_max = <span class="built_in">float</span>(label_scaler.data_max_[<span class="number">0</span>]) <span class="keyword">if</span> label_scaler <span class="keyword">else</span> <span class="number">1.0</span></span><br><span class="line"></span><br><span class="line">    stats = &#123;</span><br><span class="line">        <span class="string">&#x27;mean&#x27;</span>: mean,</span><br><span class="line">        <span class="string">&#x27;std&#x27;</span>: std,</span><br><span class="line">        <span class="string">&#x27;toxin_min&#x27;</span>: toxin_min,</span><br><span class="line">        <span class="string">&#x27;toxin_max&#x27;</span>: toxin_max</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(cache_path, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            json.dump(stats, f)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Statistics computed and saved to <span class="subst">&#123;cache_path&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="keyword">except</span> OSError <span class="keyword">as</span> e:</span><br><span class="line">        <span class="keyword">if</span> e.errno == <span class="number">28</span>:  <span class="comment"># No space left on device</span></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;Warning: No space left on device, skipping stats cache. Stats computed successfully.&quot;</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;Warning: Failed to save stats cache: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> mean, std, toxin_min, toxin_max</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">_infer_common_channels</span>(<span class="params">npy_paths, sample_limit=<span class="number">32</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Infer a common channel count across a subset of files (min channels).&quot;&quot;&quot;</span></span><br><span class="line">    chans = []</span><br><span class="line">    <span class="keyword">for</span> p <span class="keyword">in</span> npy_paths[:sample_limit]:</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            arr = np.load(p, mmap_mode=<span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">            <span class="keyword">if</span> arr.ndim == <span class="number">1</span>:</span><br><span class="line">                <span class="comment"># Try to infer channels from 1D array</span></span><br><span class="line">                total_size = arr.size</span><br><span class="line">                <span class="keyword">for</span> channels <span class="keyword">in</span> [<span class="number">300</span>, <span class="number">600</span>, <span class="number">900</span>, <span class="number">1200</span>]:</span><br><span class="line">                    spatial_size = total_size // channels</span><br><span class="line">                    spatial_dim = <span class="built_in">int</span>(np.sqrt(spatial_size))</span><br><span class="line">                    <span class="keyword">if</span> spatial_dim * spatial_dim * channels == total_size:</span><br><span class="line">                        chans.append(channels)</span><br><span class="line">                        <span class="keyword">break</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="comment"># Assume single channel if can&#x27;t determine</span></span><br><span class="line">                    spatial_dim = <span class="built_in">int</span>(np.sqrt(total_size))</span><br><span class="line">                    <span class="keyword">if</span> spatial_dim * spatial_dim == total_size:</span><br><span class="line">                        chans.append(<span class="number">1</span>)</span><br><span class="line">            <span class="keyword">elif</span> arr.ndim == <span class="number">2</span>:</span><br><span class="line">                chans.append(<span class="number">1</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                chans.append(arr.shape[<span class="number">2</span>])</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;Warning: Failed to process <span class="subst">&#123;p&#125;</span>: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> chans:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">    common_channels = <span class="built_in">min</span>(chans)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Detected channels: <span class="subst">&#123;chans[:<span class="number">10</span>]&#125;</span>... (first 10), using min: <span class="subst">&#123;common_channels&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">int</span>(common_channels)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">preprocess_data</span>(<span class="params">data_folder, batch_size=<span class="number">16</span>, target_size=(<span class="params"><span class="number">256</span>, <span class="number">256</span></span>)</span>):</span><br><span class="line">    metadata_path = os.path.join(data_folder, <span class="string">&#x27;new_metadata.csv&#x27;</span>)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(metadata_path):</span><br><span class="line">        <span class="keyword">raise</span> FileNotFoundError(<span class="string">f&quot;Metadata file <span class="subst">&#123;metadata_path&#125;</span> not found&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    metadata = pd.read_csv(metadata_path, encoding=<span class="string">&#x27;utf-8-sig&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Check required columns</span></span><br><span class="line">    required_base = [<span class="string">&#x27;toxin_value&#x27;</span>, <span class="string">&#x27;Value_Raw&#x27;</span>]</span><br><span class="line">    <span class="keyword">for</span> col <span class="keyword">in</span> required_base:</span><br><span class="line">        <span class="keyword">if</span> col <span class="keyword">not</span> <span class="keyword">in</span> metadata.columns:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">f&quot;Required column &#x27;<span class="subst">&#123;col&#125;</span>&#x27; not found in metadata.csv&quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> (<span class="string">&#x27;npy_filename&#x27;</span> <span class="keyword">not</span> <span class="keyword">in</span> metadata.columns) <span class="keyword">and</span> (<span class="string">&#x27;filename&#x27;</span> <span class="keyword">not</span> <span class="keyword">in</span> metadata.columns):</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">&quot;metadata.csv must contain &#x27;npy_filename&#x27; or &#x27;filename&#x27;&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Create label scaler using MinMaxScaler to [0,1] range</span></span><br><span class="line">    toxin_values = metadata[<span class="string">&#x27;toxin_value&#x27;</span>].values.reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">    label_scaler = MinMaxScaler(feature_range=(<span class="number">0</span>, <span class="number">1</span>))</span><br><span class="line">    label_scaler.fit(toxin_values)</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Toxin value normalization parameters: min=<span class="subst">&#123;label_scaler.data_min_[<span class="number">0</span>]&#125;</span>, max=<span class="subst">&#123;label_scaler.data_max_[<span class="number">0</span>]&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Create feature scaler</span></span><br><span class="line">    raw_values = metadata[<span class="string">&#x27;Value_Raw&#x27;</span>].values.reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">    feature_scaler = StandardScaler().fit(raw_values)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Value_Raw normalization: mean=<span class="subst">&#123;feature_scaler.mean_[<span class="number">0</span>]&#125;</span>, std=<span class="subst">&#123;feature_scaler.scale_[<span class="number">0</span>]&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Peek metadata to infer channels</span></span><br><span class="line">    meta = pd.read_csv(metadata_path, encoding=<span class="string">&#x27;utf-8-sig&#x27;</span>)</span><br><span class="line">    npy_col = <span class="string">&#x27;npy_filename&#x27;</span> <span class="keyword">if</span> <span class="string">&#x27;npy_filename&#x27;</span> <span class="keyword">in</span> meta.columns <span class="keyword">else</span> <span class="string">&#x27;filename&#x27;</span></span><br><span class="line">    npy_paths = []</span><br><span class="line">    <span class="keyword">for</span> _, r <span class="keyword">in</span> meta.iterrows():</span><br><span class="line">        p = <span class="built_in">str</span>(r[npy_col]).strip()</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.isabs(p):</span><br><span class="line">            p = os.path.join(data_folder, p)</span><br><span class="line">        <span class="keyword">if</span> os.path.isfile(p):</span><br><span class="line">            npy_paths.append(os.path.normpath(p))</span><br><span class="line">    target_channels = _infer_common_channels(npy_paths)</span><br><span class="line">    <span class="keyword">if</span> target_channels <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">raise</span> RuntimeError(<span class="string">&quot;Failed to infer common channel count from npy files&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Using common spectral channels: <span class="subst">&#123;target_channels&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Create temporary dataset for statistics</span></span><br><span class="line">    full_dataset_for_stats = HyperspectralDataset(</span><br><span class="line">        data_folder,</span><br><span class="line">        target_size=target_size,</span><br><span class="line">        scaler=<span class="literal">None</span>,</span><br><span class="line">        feature_scaler=<span class="literal">None</span>,</span><br><span class="line">        target_channels=target_channels</span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Compute or load mean and std, and save toxin normalization parameters</span></span><br><span class="line">    mean, std, toxin_min, toxin_max = compute_or_load_stats(</span><br><span class="line">        full_dataset_for_stats, </span><br><span class="line">        os.path.join(data_folder, <span class="string">&#x27;stats.json&#x27;</span>),</span><br><span class="line">        label_scaler=label_scaler</span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Toxin value normalization parameters saved: min=<span class="subst">&#123;toxin_min&#125;</span>, max=<span class="subst">&#123;toxin_max&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Data augmentation</span></span><br><span class="line">    train_transform = transforms.Compose([</span><br><span class="line">        transforms.RandomHorizontalFlip(),</span><br><span class="line">        transforms.RandomVerticalFlip(),</span><br><span class="line">        transforms.RandomRotation(degrees=<span class="number">15</span>),</span><br><span class="line">        transforms.RandomAffine(degrees=<span class="number">0</span>, translate=(<span class="number">0.05</span>, <span class="number">0.05</span>)),</span><br><span class="line">        transforms.Normalize(mean, std)</span><br><span class="line">    ])</span><br><span class="line">    test_transform = transforms.Compose([</span><br><span class="line">        transforms.Normalize(mean, std)</span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Create full datasets</span></span><br><span class="line">    full_dataset_train = HyperspectralDataset(</span><br><span class="line">        data_folder, </span><br><span class="line">        target_size=target_size, </span><br><span class="line">        transform=train_transform, </span><br><span class="line">        scaler=label_scaler,</span><br><span class="line">        feature_scaler=feature_scaler,</span><br><span class="line">        target_channels=target_channels</span><br><span class="line">    )</span><br><span class="line">    full_dataset_test = HyperspectralDataset(</span><br><span class="line">        data_folder, </span><br><span class="line">        target_size=target_size, </span><br><span class="line">        transform=test_transform, </span><br><span class="line">        scaler=label_scaler,</span><br><span class="line">        feature_scaler=feature_scaler,</span><br><span class="line">        target_channels=target_channels</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Split into train and test sets</span></span><br><span class="line">    train_idx, test_idx = train_test_split(</span><br><span class="line">        np.arange(<span class="built_in">len</span>(full_dataset_train)), </span><br><span class="line">        test_size=<span class="number">0.2</span>, </span><br><span class="line">        random_state=<span class="number">24</span></span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Create subsets</span></span><br><span class="line">    train_set = Subset(full_dataset_train, train_idx)</span><br><span class="line">    test_set = Subset(full_dataset_test, test_idx)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Create data loaders</span></span><br><span class="line">    nw = <span class="built_in">min</span>(<span class="number">4</span>, (os.cpu_count() <span class="keyword">or</span> <span class="number">1</span>))</span><br><span class="line">    train_loader = DataLoader(</span><br><span class="line">        train_set,</span><br><span class="line">        batch_size=batch_size,</span><br><span class="line">        shuffle=<span class="literal">True</span>,</span><br><span class="line">        num_workers=nw,</span><br><span class="line">        pin_memory=<span class="literal">True</span>,</span><br><span class="line">        persistent_workers=(nw &gt; <span class="number">0</span>)</span><br><span class="line">    )</span><br><span class="line">    test_loader = DataLoader(</span><br><span class="line">        test_set,</span><br><span class="line">        batch_size=batch_size,</span><br><span class="line">        shuffle=<span class="literal">False</span>,</span><br><span class="line">        num_workers=nw,</span><br><span class="line">        pin_memory=<span class="literal">True</span>,</span><br><span class="line">        persistent_workers=(nw &gt; <span class="number">0</span>)</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> train_loader, test_loader, label_scaler, feature_scaler</span><br><span class="line"></span><br><span class="line"><span class="comment"># ========================== CBAM Module Implementation ==========================</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ChannelAttention</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Channel Attention Module&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, reduction_ratio=<span class="number">16</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(ChannelAttention, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.avg_pool = nn.AdaptiveAvgPool2d(<span class="number">1</span>)</span><br><span class="line">        <span class="variable language_">self</span>.max_pool = nn.AdaptiveMaxPool2d(<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="variable language_">self</span>.fc = nn.Sequential(</span><br><span class="line">            nn.Linear(in_channels, in_channels // reduction_ratio),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Linear(in_channels // reduction_ratio, in_channels),</span><br><span class="line">            nn.Sigmoid()</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        avg_out = <span class="variable language_">self</span>.fc(<span class="variable language_">self</span>.avg_pool(x).view(x.size(<span class="number">0</span>), -<span class="number">1</span>))</span><br><span class="line">        max_out = <span class="variable language_">self</span>.fc(<span class="variable language_">self</span>.max_pool(x).view(x.size(<span class="number">0</span>), -<span class="number">1</span>))</span><br><span class="line">        out = avg_out + max_out</span><br><span class="line">        <span class="keyword">return</span> out.view(x.size(<span class="number">0</span>), x.size(<span class="number">1</span>), <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SpatialAttention</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Spatial Attention Module&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, kernel_size=<span class="number">7</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(SpatialAttention, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="keyword">assert</span> kernel_size <span class="keyword">in</span> (<span class="number">3</span>, <span class="number">7</span>), <span class="string">&quot;kernel size must be 3 or 7&quot;</span></span><br><span class="line">        padding = <span class="number">3</span> <span class="keyword">if</span> kernel_size == <span class="number">7</span> <span class="keyword">else</span> <span class="number">1</span></span><br><span class="line">        </span><br><span class="line">        <span class="variable language_">self</span>.conv = nn.Conv2d(<span class="number">2</span>, <span class="number">1</span>, kernel_size, padding=padding, bias=<span class="literal">False</span>)</span><br><span class="line">        <span class="variable language_">self</span>.sigmoid = nn.Sigmoid()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        avg_out = torch.mean(x, dim=<span class="number">1</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line">        max_out, _ = torch.<span class="built_in">max</span>(x, dim=<span class="number">1</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line">        x = torch.cat([avg_out, max_out], dim=<span class="number">1</span>)</span><br><span class="line">        x = <span class="variable language_">self</span>.conv(x)</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.sigmoid(x)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CBAM</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;CBAM Module: Channel Attention + Spatial Attention&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, reduction_ratio=<span class="number">16</span>, kernel_size=<span class="number">7</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(CBAM, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.channel_att = ChannelAttention(in_channels, reduction_ratio)</span><br><span class="line">        <span class="variable language_">self</span>.spatial_att = SpatialAttention(kernel_size)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = x * <span class="variable language_">self</span>.channel_att(x)</span><br><span class="line">        x = x * <span class="variable language_">self</span>.spatial_att(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="comment"># ========================== Enhanced Modules ==========================</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">PositionalEncoding</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Positional Encoding for enhanced spectral information&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, d_model, max_len=<span class="number">500</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        pe = torch.zeros(max_len, d_model)</span><br><span class="line">        position = torch.arange(<span class="number">0</span>, max_len, dtype=torch.<span class="built_in">float</span>).unsqueeze(<span class="number">1</span>)</span><br><span class="line">        div_term = torch.exp(torch.arange(<span class="number">0</span>, d_model, <span class="number">2</span>).<span class="built_in">float</span>() * (-math.log(<span class="number">10000.0</span>) / d_model))</span><br><span class="line">        pe[:, <span class="number">0</span>::<span class="number">2</span>] = torch.sin(position * div_term)</span><br><span class="line">        pe[:, <span class="number">1</span>::<span class="number">2</span>] = torch.cos(position * div_term)</span><br><span class="line">        pe = pe.unsqueeze(<span class="number">0</span>)</span><br><span class="line">        <span class="variable language_">self</span>.register_buffer(<span class="string">&#x27;pe&#x27;</span>, pe)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        seq_len = x.size(<span class="number">1</span>)</span><br><span class="line">        pos_emb = <span class="variable language_">self</span>.pe[:, :seq_len, :]</span><br><span class="line">        <span class="keyword">return</span> x + pos_emb</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">GatedLinear</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Gated Linear Layer&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_features, out_features</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.linear = nn.Linear(in_features, out_features)</span><br><span class="line">        <span class="variable language_">self</span>.gate = nn.Linear(in_features, out_features)</span><br><span class="line">        nn.init.xavier_uniform_(<span class="variable language_">self</span>.linear.weight)</span><br><span class="line">        nn.init.xavier_uniform_(<span class="variable language_">self</span>.gate.weight)</span><br><span class="line">        nn.init.zeros_(<span class="variable language_">self</span>.linear.bias)</span><br><span class="line">        nn.init.zeros_(<span class="variable language_">self</span>.gate.bias)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.linear(x) * torch.sigmoid(<span class="variable language_">self</span>.gate(x))</span><br><span class="line"></span><br><span class="line"><span class="comment"># ========================== CBAM Model ==========================</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">HyperspectralModel</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_channels</span>):</span><br><span class="line">        <span class="built_in">super</span>(HyperspectralModel, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Initial feature extraction</span></span><br><span class="line">        <span class="variable language_">self</span>.conv1 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(input_channels, <span class="number">64</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">64</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        )</span><br><span class="line">        <span class="variable language_">self</span>.cbam1 = CBAM(<span class="number">64</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Downsample block 1</span></span><br><span class="line">        <span class="variable language_">self</span>.down1 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">64</span>, <span class="number">64</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">64</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            CBAM(<span class="number">64</span>)</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Downsample block 2</span></span><br><span class="line">        <span class="variable language_">self</span>.down2 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">64</span>, <span class="number">128</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">128</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">128</span>, <span class="number">128</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">128</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            CBAM(<span class="number">128</span>)</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Final feature extraction</span></span><br><span class="line">        <span class="variable language_">self</span>.final_conv = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">128</span>, <span class="number">256</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">256</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            CBAM(<span class="number">256</span>),</span><br><span class="line">            nn.AdaptiveAvgPool2d(<span class="number">1</span>)</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Fusion FC layers with Value_Raw feature</span></span><br><span class="line">        <span class="variable language_">self</span>.fc = nn.Sequential(</span><br><span class="line">            nn.Linear(<span class="number">256</span> + <span class="number">1</span>, <span class="number">512</span>),  <span class="comment"># 256 image features + 1 Value_Raw</span></span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Dropout(<span class="number">0.4</span>),</span><br><span class="line">            </span><br><span class="line">            nn.Linear(<span class="number">512</span>, <span class="number">256</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Dropout(<span class="number">0.3</span>),</span><br><span class="line">            </span><br><span class="line">            nn.Linear(<span class="number">256</span>, <span class="number">128</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Dropout(<span class="number">0.2</span>),</span><br><span class="line">            </span><br><span class="line">            nn.Linear(<span class="number">128</span>, <span class="number">1</span>)</span><br><span class="line">        )</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, feature</span>):</span><br><span class="line">        <span class="comment"># Feature extraction + CBAM attention</span></span><br><span class="line">        x = <span class="variable language_">self</span>.conv1(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.cbam1(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.down1(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.down2(x)</span><br><span class="line">        img_features = <span class="variable language_">self</span>.final_conv(x).squeeze(-<span class="number">1</span>).squeeze(-<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Concatenate with Value_Raw feature</span></span><br><span class="line">        combined = torch.cat([img_features, feature.unsqueeze(<span class="number">1</span>)], dim=<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Predict through FC layers</span></span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.fc(combined).flatten()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">visualize_attention</span>(<span class="params">self, input_tensor</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Visualize CBAM attention effects (for debugging)&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            activations = &#123;&#125;</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># First layer</span></span><br><span class="line">            x1 = <span class="variable language_">self</span>.conv1(input_tensor)</span><br><span class="line">            x1_att = <span class="variable language_">self</span>.cbam1(x1)</span><br><span class="line">            activations[<span class="string">&#x27;conv1&#x27;</span>] = x1</span><br><span class="line">            activations[<span class="string">&#x27;cbam1&#x27;</span>] = x1_att</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># Downsample 1</span></span><br><span class="line">            x2 = <span class="variable language_">self</span>.down1[:-<span class="number">1</span>](x1_att)</span><br><span class="line">            x2_att = <span class="variable language_">self</span>.down1[-<span class="number">1</span>](x2)</span><br><span class="line">            activations[<span class="string">&#x27;down1&#x27;</span>] = x2</span><br><span class="line">            activations[<span class="string">&#x27;cbam2&#x27;</span>] = x2_att</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># Downsample 2</span></span><br><span class="line">            x3 = <span class="variable language_">self</span>.down2[:-<span class="number">1</span>](x2_att)</span><br><span class="line">            x3_att = <span class="variable language_">self</span>.down2[-<span class="number">1</span>](x3)</span><br><span class="line">            activations[<span class="string">&#x27;down2&#x27;</span>] = x3</span><br><span class="line">            activations[<span class="string">&#x27;cbam3&#x27;</span>] = x3_att</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># Final layer</span></span><br><span class="line">            x4 = <span class="variable language_">self</span>.final_conv[:-<span class="number">2</span>](x3_att)</span><br><span class="line">            x4_att = <span class="variable language_">self</span>.final_conv[-<span class="number">2</span>](x4)</span><br><span class="line">            activations[<span class="string">&#x27;final_conv&#x27;</span>] = x4</span><br><span class="line">            activations[<span class="string">&#x27;cbam4&#x27;</span>] = x4_att</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">return</span> activations</span><br><span class="line"></span><br><span class="line"><span class="comment"># ========================== Training Functions ==========================</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">adjust_learning_rate</span>(<span class="params">optimizer, epoch, warmup_epochs, initial_lr, num_epochs</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Custom learning rate scheduler&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> epoch &lt; warmup_epochs:</span><br><span class="line">        lr = initial_lr * (epoch + <span class="number">1</span>) / warmup_epochs</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        progress = (epoch - warmup_epochs) / (num_epochs - warmup_epochs)</span><br><span class="line">        lr = <span class="number">0.5</span> * initial_lr * (<span class="number">1</span> + math.cos(math.pi * progress))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> param_group <span class="keyword">in</span> optimizer.param_groups:</span><br><span class="line">        param_group[<span class="string">&#x27;lr&#x27;</span>] = lr</span><br><span class="line">    <span class="keyword">return</span> lr</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">evaluate_regression</span>(<span class="params">model, loader, device=<span class="string">&#x27;cuda&#x27;</span>, scaler=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Evaluate regression model performance&quot;&quot;&quot;</span></span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    all_labels, all_preds = [], []</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> inputs, labels, features <span class="keyword">in</span> loader:</span><br><span class="line">            inputs = inputs.to(device)</span><br><span class="line">            features = features.to(device)</span><br><span class="line">            outputs = model(inputs, features).flatten()</span><br><span class="line">            all_labels.extend(labels.cpu().numpy())</span><br><span class="line">            all_preds.extend(outputs.cpu().numpy())</span><br><span class="line">    </span><br><span class="line">    all_labels = np.array(all_labels)</span><br><span class="line">    all_preds = np.array(all_preds)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Inverse transform if scaler is provided</span></span><br><span class="line">    <span class="keyword">if</span> scaler:</span><br><span class="line">        all_labels_orig = scaler.inverse_transform(all_labels.reshape(-<span class="number">1</span>, <span class="number">1</span>)).flatten()</span><br><span class="line">        all_preds_orig = scaler.inverse_transform(all_preds.reshape(-<span class="number">1</span>, <span class="number">1</span>)).flatten()</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        all_labels_orig = all_labels</span><br><span class="line">        all_preds_orig = all_preds</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Calculate metrics</span></span><br><span class="line">    mae = mean_absolute_error(all_labels_orig, all_preds_orig)</span><br><span class="line">    r2 = r2_score(all_labels_orig, all_preds_orig)</span><br><span class="line">    mse_normalized = np.mean((all_labels - all_preds)**<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> all_labels_orig, all_preds_orig, mae, r2, mse_normalized</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_regression_model</span>(<span class="params">model, train_loader, val_loader, scaler, num_epochs=<span class="number">100</span>, device=<span class="string">&#x27;cpu&#x27;</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Train regression model (evaluate every epoch)&quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># Move model to the selected device</span></span><br><span class="line">    model.to(device)</span><br><span class="line">    criterion = nn.MSELoss()</span><br><span class="line">    optimizer = optim.AdamW(model.parameters(), lr=<span class="number">1e-4</span>, weight_decay=<span class="number">1e-5</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Training parameters</span></span><br><span class="line">    warmup_epochs = <span class="number">10</span></span><br><span class="line">    best_val_loss = <span class="built_in">float</span>(<span class="string">&#x27;inf&#x27;</span>)</span><br><span class="line">    best_val_r2 = -<span class="built_in">float</span>(<span class="string">&#x27;inf&#x27;</span>)</span><br><span class="line">    patience = <span class="number">15</span></span><br><span class="line">    trigger_times = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Track training progress</span></span><br><span class="line">    train_losses = []</span><br><span class="line">    val_losses = []</span><br><span class="line">    val_r2s = []</span><br><span class="line">    best_predictions = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Starting training for <span class="subst">&#123;num_epochs&#125;</span> epochs with evaluation every epoch...&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">        model.train()</span><br><span class="line">        running_loss = <span class="number">0.0</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Adjust learning rate</span></span><br><span class="line">        current_lr = adjust_learning_rate(optimizer, epoch, warmup_epochs, <span class="number">1e-4</span>, num_epochs)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Training loop</span></span><br><span class="line">        <span class="keyword">for</span> inputs, labels, features <span class="keyword">in</span> tqdm(train_loader, desc=<span class="string">f&#x27;Epoch <span class="subst">&#123;epoch + <span class="number">1</span>&#125;</span>/<span class="subst">&#123;num_epochs&#125;</span>&#x27;</span>):</span><br><span class="line">            inputs = inputs.to(device)</span><br><span class="line">            labels = labels.to(device)</span><br><span class="line">            features = features.to(device)</span><br><span class="line">            </span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            outputs = model(inputs, features)</span><br><span class="line">            loss = criterion(outputs, labels)</span><br><span class="line">            loss.backward()</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># Gradient clipping</span></span><br><span class="line">            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=<span class="number">2.0</span>)</span><br><span class="line">            </span><br><span class="line">            optimizer.step()</span><br><span class="line">            running_loss += loss.item()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Calculate average training loss</span></span><br><span class="line">        avg_train_loss = running_loss / <span class="built_in">len</span>(train_loader)</span><br><span class="line">        train_losses.append(avg_train_loss)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Evaluate every epoch</span></span><br><span class="line">        model.<span class="built_in">eval</span>()</span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            val_labels, val_preds = [], []</span><br><span class="line">            <span class="keyword">for</span> val_inputs, val_labels_batch, val_features <span class="keyword">in</span> val_loader:</span><br><span class="line">                val_inputs = val_inputs.to(device)</span><br><span class="line">                val_features = val_features.to(device)</span><br><span class="line">                val_outputs = model(val_inputs, val_features).flatten()</span><br><span class="line">                val_labels.extend(val_labels_batch.cpu().numpy())</span><br><span class="line">                val_preds.extend(val_outputs.cpu().numpy())</span><br><span class="line">            </span><br><span class="line">            val_labels = np.array(val_labels)</span><br><span class="line">            val_preds = np.array(val_preds)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># Inverse transform if scaler is provided</span></span><br><span class="line">            <span class="keyword">if</span> scaler:</span><br><span class="line">                val_labels_orig = scaler.inverse_transform(val_labels.reshape(-<span class="number">1</span>, <span class="number">1</span>)).flatten()</span><br><span class="line">                val_preds_orig = scaler.inverse_transform(val_preds.reshape(-<span class="number">1</span>, <span class="number">1</span>)).flatten()</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                val_labels_orig = val_labels</span><br><span class="line">                val_preds_orig = val_preds</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Calculate metrics</span></span><br><span class="line">            val_mae = mean_absolute_error(val_labels_orig, val_preds_orig)</span><br><span class="line">            val_r2 = r2_score(val_labels_orig, val_preds_orig)</span><br><span class="line">            val_loss_normalized = np.mean((val_labels - val_preds)**<span class="number">2</span>)</span><br><span class="line">        </span><br><span class="line">        val_losses.append(val_loss_normalized)</span><br><span class="line">        val_r2s.append(val_r2)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Check for improvement</span></span><br><span class="line">        r2_improved = (val_r2 - best_val_r2) &gt; <span class="number">0.001</span></span><br><span class="line">        loss_improved = (best_val_loss - val_loss_normalized) &gt; <span class="number">0.01</span></span><br><span class="line">        improvement = r2_improved <span class="keyword">or</span> loss_improved</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> improvement:</span><br><span class="line">            best_val_r2 = val_r2</span><br><span class="line">            best_val_loss = val_loss_normalized</span><br><span class="line">            trigger_times = <span class="number">0</span></span><br><span class="line">            best_predictions = (val_labels_orig, val_preds_orig)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># Save model</span></span><br><span class="line">            save_dict = &#123;</span><br><span class="line">                <span class="string">&#x27;epoch&#x27;</span>: epoch,</span><br><span class="line">                <span class="string">&#x27;model_state_dict&#x27;</span>: model.state_dict(),</span><br><span class="line">                <span class="string">&#x27;optimizer_state_dict&#x27;</span>: optimizer.state_dict(),</span><br><span class="line">                <span class="string">&#x27;loss&#x27;</span>: best_val_loss,</span><br><span class="line">                <span class="string">&#x27;r2&#x27;</span>: best_val_r2,</span><br><span class="line">            &#125;</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># Add toxin normalization parameters</span></span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">hasattr</span>(scaler, <span class="string">&#x27;data_min_&#x27;</span>) <span class="keyword">and</span> <span class="built_in">hasattr</span>(scaler, <span class="string">&#x27;data_max_&#x27;</span>):</span><br><span class="line">                save_dict[<span class="string">&#x27;toxin_min&#x27;</span>] = scaler.data_min_[<span class="number">0</span>]</span><br><span class="line">                save_dict[<span class="string">&#x27;toxin_max&#x27;</span>] = scaler.data_max_[<span class="number">0</span>]</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                torch.save(save_dict, <span class="string">&#x27;best_model.pth&#x27;</span>)</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;✔ Validation metrics improved, saving model. R²: <span class="subst">&#123;best_val_r2:<span class="number">.4</span>f&#125;</span>, Loss: <span class="subst">&#123;val_loss_normalized:<span class="number">.4</span>f&#125;</span> (Epoch <span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span>)&quot;</span>)</span><br><span class="line">            <span class="keyword">except</span> OSError <span class="keyword">as</span> e:</span><br><span class="line">                <span class="keyword">if</span> e.errno == <span class="number">28</span>:  <span class="comment"># No space left on device</span></span><br><span class="line">                    <span class="built_in">print</span>(<span class="string">f&quot;✔ Validation metrics improved but cannot save model (no space). R²: <span class="subst">&#123;best_val_r2:<span class="number">.4</span>f&#125;</span>, Loss: <span class="subst">&#123;val_loss_normalized:<span class="number">.4</span>f&#125;</span> (Epoch <span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span>)&quot;</span>)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="built_in">print</span>(<span class="string">f&quot;✔ Validation metrics improved but failed to save model: <span class="subst">&#123;e&#125;</span>. R²: <span class="subst">&#123;best_val_r2:<span class="number">.4</span>f&#125;</span>, Loss: <span class="subst">&#123;val_loss_normalized:<span class="number">.4</span>f&#125;</span> (Epoch <span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span>)&quot;</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            trigger_times += <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> trigger_times &gt;= patience:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;Early stopping triggered! No improvement for <span class="subst">&#123;patience&#125;</span> consecutive epochs.&quot;</span>)</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Print training status</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Epoch <span class="subst">&#123;epoch + <span class="number">1</span>&#125;</span>/<span class="subst">&#123;num_epochs&#125;</span> | LR: <span class="subst">&#123;current_lr:<span class="number">.2</span>e&#125;</span> | &quot;</span></span><br><span class="line">              <span class="string">f&quot;Train Loss: <span class="subst">&#123;avg_train_loss:<span class="number">.4</span>f&#125;</span> | &quot;</span></span><br><span class="line">              <span class="string">f&quot;Val Loss: <span class="subst">&#123;val_loss_normalized:<span class="number">.4</span>f&#125;</span> | &quot;</span></span><br><span class="line">              <span class="string">f&quot;Val R²: <span class="subst">&#123;val_r2:<span class="number">.4</span>f&#125;</span> | &quot;</span></span><br><span class="line">              <span class="string">f&quot;Trigger: <span class="subst">&#123;trigger_times&#125;</span>/<span class="subst">&#123;patience&#125;</span>&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Training complete, load best model</span></span><br><span class="line">    <span class="keyword">if</span> os.path.exists(<span class="string">&#x27;best_model.pth&#x27;</span>):</span><br><span class="line">        checkpoint = torch.load(<span class="string">&#x27;best_model.pth&#x27;</span>)</span><br><span class="line">        model.load_state_dict(checkpoint[<span class="string">&#x27;model_state_dict&#x27;</span>])</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;\nTraining complete. Best model at epoch <span class="subst">&#123;checkpoint[<span class="string">&#x27;epoch&#x27;</span>] + <span class="number">1</span>&#125;</span>: &quot;</span></span><br><span class="line">              <span class="string">f&quot;R²: <span class="subst">&#123;checkpoint[<span class="string">&#x27;r2&#x27;</span>]:<span class="number">.4</span>f&#125;</span>, Loss: <span class="subst">&#123;checkpoint[<span class="string">&#x27;loss&#x27;</span>]:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> <span class="string">&#x27;toxin_min&#x27;</span> <span class="keyword">in</span> checkpoint <span class="keyword">and</span> <span class="string">&#x27;toxin_max&#x27;</span> <span class="keyword">in</span> checkpoint:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;Toxin min=<span class="subst">&#123;checkpoint[<span class="string">&#x27;toxin_min&#x27;</span>]&#125;</span>, Toxin max=<span class="subst">&#123;checkpoint[<span class="string">&#x27;toxin_max&#x27;</span>]&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;\nTraining complete, but no model saved.&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Visualize training progress</span></span><br><span class="line">    visualize_training(train_losses, val_losses, val_r2s, <span class="built_in">min</span>(num_epochs, <span class="built_in">len</span>(val_losses)))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> best_predictions</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">visualize_training</span>(<span class="params">train_losses, val_losses, val_r2s, num_epochs</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Visualize training progress&quot;&quot;&quot;</span></span><br><span class="line">    plt.figure(figsize=(<span class="number">12</span>, <span class="number">8</span>))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Loss curves</span></span><br><span class="line">    epochs = np.arange(<span class="number">1</span>, <span class="built_in">len</span>(train_losses) + <span class="number">1</span>)</span><br><span class="line">    plt.subplot(<span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">    plt.plot(epochs, train_losses, <span class="string">&#x27;b-&#x27;</span>, label=<span class="string">&#x27;Train Loss&#x27;</span>)</span><br><span class="line">    <span class="keyword">if</span> val_losses:</span><br><span class="line">        eval_points = np.linspace(<span class="number">0</span>, num_epochs, <span class="built_in">len</span>(val_losses), endpoint=<span class="literal">False</span>).astype(<span class="built_in">int</span>) + <span class="number">1</span></span><br><span class="line">        plt.plot(eval_points, val_losses, <span class="string">&#x27;r-&#x27;</span>, label=<span class="string">&#x27;Val Loss&#x27;</span>)</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;Epoch&#x27;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;Loss&#x27;</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;Training and Validation Loss&#x27;</span>)</span><br><span class="line">    plt.legend()</span><br><span class="line">    plt.grid(<span class="literal">True</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># R² curve</span></span><br><span class="line">    plt.subplot(<span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">    <span class="keyword">if</span> val_r2s:</span><br><span class="line">        plt.plot(eval_points, val_r2s, <span class="string">&#x27;g-&#x27;</span>, label=<span class="string">&#x27;Val R²&#x27;</span>)</span><br><span class="line">    plt.axhline(y=<span class="number">0</span>, color=<span class="string">&#x27;k&#x27;</span>, linestyle=<span class="string">&#x27;--&#x27;</span>, alpha=<span class="number">0.5</span>)</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;Epoch&#x27;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;R² Score&#x27;</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;Validation R² Score&#x27;</span>)</span><br><span class="line">    plt.ylim(-<span class="number">0.5</span>, <span class="number">1.0</span>)</span><br><span class="line">    plt.grid(<span class="literal">True</span>)</span><br><span class="line">    </span><br><span class="line">    plt.tight_layout()</span><br><span class="line">    plt.savefig(<span class="string">&#x27;training_metrics.png&#x27;</span>, dpi=<span class="number">300</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">enhanced_visualization</span>(<span class="params">true_values, pred_values</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Enhanced regression result visualization&quot;&quot;&quot;</span></span><br><span class="line">    plt.figure(figsize=(<span class="number">18</span>, <span class="number">12</span>))</span><br><span class="line">    residuals = pred_values - true_values</span><br><span class="line">    abs_errors = np.<span class="built_in">abs</span>(residuals)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Figure 1: True vs Predicted</span></span><br><span class="line">    plt.subplot(<span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">    sns.regplot(x=true_values, y=pred_values, </span><br><span class="line">                scatter_kws=&#123;<span class="string">&#x27;alpha&#x27;</span>:<span class="number">0.4</span>, <span class="string">&#x27;color&#x27;</span>:<span class="string">&#x27;#4B8BBE&#x27;</span>&#125;, </span><br><span class="line">                line_kws=&#123;<span class="string">&#x27;color&#x27;</span>:<span class="string">&#x27;#FF0000&#x27;</span>, <span class="string">&#x27;lw&#x27;</span>:<span class="number">2</span>&#125;,</span><br><span class="line">                ci=<span class="number">95</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Add metrics</span></span><br><span class="line">    mae = mean_absolute_error(true_values, pred_values)</span><br><span class="line">    r2 = r2_score(true_values, pred_values)</span><br><span class="line">    rmse = np.sqrt(mean_squared_error(true_values, pred_values))</span><br><span class="line">    textstr = <span class="string">&#x27;\n&#x27;</span>.join((</span><br><span class="line">        <span class="string">f&#x27;MAE = <span class="subst">&#123;mae:<span class="number">.2</span>f&#125;</span>&#x27;</span>,</span><br><span class="line">        <span class="string">f&#x27;RMSE = <span class="subst">&#123;rmse:<span class="number">.2</span>f&#125;</span>&#x27;</span>,</span><br><span class="line">        <span class="string">f&#x27;R² = <span class="subst">&#123;r2:<span class="number">.2</span>f&#125;</span>&#x27;</span>))</span><br><span class="line">    </span><br><span class="line">    plt.gca().text(<span class="number">0.05</span>, <span class="number">0.95</span>, textstr, transform=plt.gca().transAxes,</span><br><span class="line">                   fontsize=<span class="number">12</span>, verticalalignment=<span class="string">&#x27;top&#x27;</span>,</span><br><span class="line">                   bbox=<span class="built_in">dict</span>(facecolor=<span class="string">&#x27;white&#x27;</span>, alpha=<span class="number">0.8</span>))</span><br><span class="line">    </span><br><span class="line">    plt.plot([<span class="built_in">min</span>(true_values), <span class="built_in">max</span>(true_values)], </span><br><span class="line">             [<span class="built_in">min</span>(true_values), <span class="built_in">max</span>(true_values)], </span><br><span class="line">             <span class="string">&#x27;k--&#x27;</span>, lw=<span class="number">1</span>, label=<span class="string">&#x27;Perfect Prediction&#x27;</span>)</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;True Values&#x27;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;Predictions&#x27;</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;True vs Predicted Values&#x27;</span>)</span><br><span class="line">    plt.legend()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Figure 2: Residual analysis</span></span><br><span class="line">    plt.subplot(<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">    sns.residplot(x=true_values, y=residuals, </span><br><span class="line">                  lowess=<span class="literal">True</span>, </span><br><span class="line">                  scatter_kws=&#123;<span class="string">&#x27;alpha&#x27;</span>:<span class="number">0.4</span>, <span class="string">&#x27;color&#x27;</span>:<span class="string">&#x27;#4B8BBE&#x27;</span>&#125;,</span><br><span class="line">                  line_kws=&#123;<span class="string">&#x27;color&#x27;</span>:<span class="string">&#x27;#FF0000&#x27;</span>, <span class="string">&#x27;lw&#x27;</span>:<span class="number">2</span>&#125;)</span><br><span class="line">    </span><br><span class="line">    plt.axhline(y=<span class="number">0</span>, color=<span class="string">&#x27;k&#x27;</span>, linestyle=<span class="string">&#x27;--&#x27;</span>, lw=<span class="number">1</span>)</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;True Values&#x27;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;Residuals&#x27;</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;Residual Analysis&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Figure 3: Error distribution</span></span><br><span class="line">    plt.subplot(<span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line">    sns.histplot(abs_errors, kde=<span class="literal">True</span>, </span><br><span class="line">                 bins=<span class="number">30</span>, color=<span class="string">&#x27;#4B8BBE&#x27;</span>,</span><br><span class="line">                 edgecolor=<span class="string">&#x27;white&#x27;</span>, linewidth=<span class="number">0.5</span>)</span><br><span class="line">    </span><br><span class="line">    plt.axvline(x=mae, color=<span class="string">&#x27;r&#x27;</span>, linestyle=<span class="string">&#x27;--&#x27;</span>, lw=<span class="number">2</span>,</span><br><span class="line">                label=<span class="string">f&#x27;MAE = <span class="subst">&#123;mae:<span class="number">.2</span>f&#125;</span>&#x27;</span>)</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;Absolute Error&#x27;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;Count&#x27;</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;Absolute Error Distribution&#x27;</span>)</span><br><span class="line">    plt.legend()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Figure 4: Prediction error</span></span><br><span class="line">    plt.subplot(<span class="number">2</span>, <span class="number">2</span>, <span class="number">4</span>)</span><br><span class="line">    plt.scatter(true_values, residuals, alpha=<span class="number">0.5</span>, color=<span class="string">&#x27;#4B8BBE&#x27;</span>)</span><br><span class="line">    plt.axhline(y=<span class="number">0</span>, color=<span class="string">&#x27;r&#x27;</span>, linestyle=<span class="string">&#x27;--&#x27;</span>, lw=<span class="number">1</span>)</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;True Values&#x27;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;Prediction Error&#x27;</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;Prediction Error Distribution&#x27;</span>)</span><br><span class="line">    plt.grid(<span class="literal">True</span>)</span><br><span class="line">    plt.tight_layout()</span><br><span class="line">    plt.savefig(<span class="string">&#x27;enhanced_regression_analysis.png&#x27;</span>, dpi=<span class="number">300</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    data_folder = <span class="string">&quot;/Volumes/Extreme Pro/001-实验数据-是这个/001-是这个/test/processed_npy&quot;</span> </span><br><span class="line">    batch_size = <span class="number">16</span></span><br><span class="line">    num_epochs = <span class="number">100</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;--- Data Preprocessing ---&quot;</span>)</span><br><span class="line">    train_loader, test_loader, label_scaler, feature_scaler = preprocess_data(data_folder, batch_size)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Select device automatically</span></span><br><span class="line">    device = get_best_device()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Using device: <span class="subst">&#123;device&#125;</span>&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        sample_data, _, _ = <span class="built_in">next</span>(<span class="built_in">iter</span>(train_loader))</span><br><span class="line">        input_channels = sample_data.shape[<span class="number">1</span>]</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Detected input channels: <span class="subst">&#123;input_channels&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="keyword">except</span> StopIteration:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Train loader is empty. Check data folder and metadata file.&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;--- Model Creation ---&quot;</span>)</span><br><span class="line">    model = HyperspectralModel(input_channels)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Print model parameters</span></span><br><span class="line">    total_params = <span class="built_in">sum</span>(p.numel() <span class="keyword">for</span> p <span class="keyword">in</span> model.parameters())</span><br><span class="line">    trainable_params = <span class="built_in">sum</span>(p.numel() <span class="keyword">for</span> p <span class="keyword">in</span> model.parameters() <span class="keyword">if</span> p.requires_grad)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Total parameters: <span class="subst">&#123;total_params:,&#125;</span> | Trainable parameters: <span class="subst">&#123;trainable_params:,&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;--- Model Training ---&quot;</span>)</span><br><span class="line">    best_predictions = train_regression_model(</span><br><span class="line">        model, </span><br><span class="line">        train_loader, </span><br><span class="line">        test_loader, </span><br><span class="line">        label_scaler, </span><br><span class="line">        num_epochs=num_epochs,</span><br><span class="line">        device=device</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\n--- Final Model Evaluation ---&quot;</span>)</span><br><span class="line">    <span class="comment"># Load best model for final evaluation</span></span><br><span class="line">    <span class="keyword">if</span> os.path.exists(<span class="string">&#x27;best_model.pth&#x27;</span>):</span><br><span class="line">        checkpoint = torch.load(<span class="string">&#x27;best_model.pth&#x27;</span>)</span><br><span class="line">        model.load_state_dict(checkpoint[<span class="string">&#x27;model_state_dict&#x27;</span>])</span><br><span class="line">        </span><br><span class="line">        final_labels_orig, final_preds_orig, final_mae, final_r2, _ = evaluate_regression(</span><br><span class="line">            model, test_loader, device=device, scaler=label_scaler</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Final performance on test set:&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;MAE (original scale): <span class="subst">&#123;final_mae:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;R² Score (original scale): <span class="subst">&#123;final_r2:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Best model achieved R²: <span class="subst">&#123;checkpoint[<span class="string">&#x27;r2&#x27;</span>]:<span class="number">.4</span>f&#125;</span> at epoch <span class="subst">&#123;checkpoint[<span class="string">&#x27;epoch&#x27;</span>] + <span class="number">1</span>&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Visualize predictions</span></span><br><span class="line">        enhanced_visualization(final_labels_orig, final_preds_orig)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Visualize best predictions (if available)</span></span><br><span class="line">        <span class="keyword">if</span> best_predictions:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;\nVisualizing best predictions...&quot;</span>)</span><br><span class="line">            best_labels, best_preds = best_predictions</span><br><span class="line">            enhanced_visualization(best_labels, best_preds)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;No saved model found, using current model for evaluation&quot;</span>)</span><br><span class="line">        final_labels_orig, final_preds_orig, final_mae, final_r2, _ = evaluate_regression(</span><br><span class="line">            model, test_loader, device=device, scaler=label_scaler</span><br><span class="line">        )</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Final performance on test set:&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;MAE (original scale): <span class="subst">&#123;final_mae:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;R² Score (original scale): <span class="subst">&#123;final_r2:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line">        enhanced_visualization(final_labels_orig, final_preds_orig)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br><span class="line">429</span><br><span class="line">430</span><br><span class="line">431</span><br><span class="line">432</span><br><span class="line">433</span><br><span class="line">434</span><br><span class="line">435</span><br><span class="line">436</span><br><span class="line">437</span><br><span class="line">438</span><br><span class="line">439</span><br><span class="line">440</span><br><span class="line">441</span><br><span class="line">442</span><br><span class="line">443</span><br><span class="line">444</span><br><span class="line">445</span><br><span class="line">446</span><br><span class="line">447</span><br><span class="line">448</span><br><span class="line">449</span><br><span class="line">450</span><br><span class="line">451</span><br><span class="line">452</span><br><span class="line">453</span><br><span class="line">454</span><br><span class="line">455</span><br><span class="line">456</span><br><span class="line">457</span><br><span class="line">458</span><br><span class="line">459</span><br><span class="line">460</span><br><span class="line">461</span><br><span class="line">462</span><br><span class="line">463</span><br><span class="line">464</span><br><span class="line">465</span><br><span class="line">466</span><br><span class="line">467</span><br><span class="line">468</span><br><span class="line">469</span><br><span class="line">470</span><br><span class="line">471</span><br><span class="line">472</span><br><span class="line">473</span><br><span class="line">474</span><br><span class="line">475</span><br><span class="line">476</span><br><span class="line">477</span><br><span class="line">478</span><br><span class="line">479</span><br><span class="line">480</span><br><span class="line">481</span><br><span class="line">482</span><br><span class="line">483</span><br><span class="line">484</span><br><span class="line">485</span><br><span class="line">486</span><br><span class="line">487</span><br><span class="line">488</span><br><span class="line">489</span><br><span class="line">490</span><br><span class="line">491</span><br><span class="line">492</span><br><span class="line">493</span><br><span class="line">494</span><br><span class="line">495</span><br><span class="line">496</span><br><span class="line">497</span><br><span class="line">498</span><br><span class="line">499</span><br><span class="line">500</span><br><span class="line">501</span><br><span class="line">502</span><br><span class="line">503</span><br><span class="line">504</span><br><span class="line">505</span><br><span class="line">506</span><br><span class="line">507</span><br><span class="line">508</span><br><span class="line">509</span><br><span class="line">510</span><br><span class="line">511</span><br><span class="line">512</span><br><span class="line">513</span><br><span class="line">514</span><br><span class="line">515</span><br><span class="line">516</span><br><span class="line">517</span><br><span class="line">518</span><br><span class="line">519</span><br><span class="line">520</span><br><span class="line">521</span><br><span class="line">522</span><br><span class="line">523</span><br><span class="line">524</span><br><span class="line">525</span><br><span class="line">526</span><br><span class="line">527</span><br><span class="line">528</span><br><span class="line">529</span><br><span class="line">530</span><br><span class="line">531</span><br><span class="line">532</span><br><span class="line">533</span><br><span class="line">534</span><br><span class="line">535</span><br><span class="line">536</span><br><span class="line">537</span><br><span class="line">538</span><br><span class="line">539</span><br><span class="line">540</span><br><span class="line">541</span><br><span class="line">542</span><br><span class="line">543</span><br><span class="line">544</span><br><span class="line">545</span><br><span class="line">546</span><br><span class="line">547</span><br><span class="line">548</span><br><span class="line">549</span><br><span class="line">550</span><br><span class="line">551</span><br><span class="line">552</span><br><span class="line">553</span><br><span class="line">554</span><br><span class="line">555</span><br><span class="line">556</span><br><span class="line">557</span><br><span class="line">558</span><br><span class="line">559</span><br><span class="line">560</span><br><span class="line">561</span><br><span class="line">562</span><br><span class="line">563</span><br><span class="line">564</span><br><span class="line">565</span><br><span class="line">566</span><br><span class="line">567</span><br><span class="line">568</span><br><span class="line">569</span><br><span class="line">570</span><br><span class="line">571</span><br><span class="line">572</span><br><span class="line">573</span><br><span class="line">574</span><br><span class="line">575</span><br><span class="line">576</span><br><span class="line">577</span><br><span class="line">578</span><br><span class="line">579</span><br><span class="line">580</span><br><span class="line">581</span><br><span class="line">582</span><br><span class="line">583</span><br><span class="line">584</span><br><span class="line">585</span><br><span class="line">586</span><br></pre></td><td class="code"><pre><span class="line">#!/usr/bin/env python3</span><br><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">ENVI (.hdr/.spe) 转换为 .npy + 生成元数据 CSV 的预处理脚本</span><br><span class="line"></span><br><span class="line">使用示例：</span><br><span class="line">	python scripts/prepare_npy_from_envi.py \</span><br><span class="line">		--excel &quot;/Volumes/Extreme Pro/001-实验数据-是这个/001-是这个/20251015-数据统计-是这个.xlsx&quot; \</span><br><span class="line">		--data_root &quot;/Volumes/Extreme Pro/001-实验数据-是这个/001-是这个/001-高光谱-是这个&quot; \</span><br><span class="line">		--out_dir &quot;/Volumes/Extreme Pro/001-实验数据-是这个/001-是这个/test/processed_npy&quot; \</span><br><span class="line">		--metadata &quot;/Volumes/Extreme Pro/001-实验数据-是这个/001-是这个/test/processed_npy/new_metadata.csv&quot;</span><br><span class="line"></span><br><span class="line">功能概述：</span><br><span class="line">	1) 从 Excel 读取三列：</span><br><span class="line">		 - Sample Name：用于定位 ENVI 文件（支持每 40 个样本分卷：如 6H、6H-2，编号在第二卷从 1 重新开始）</span><br><span class="line">		 - Area：写入 Value_Raw</span><br><span class="line">		 - Toxic content：写入 toxin_value</span><br><span class="line">	2) 在 data_root 下寻找对应 .hdr/.spe，读取为 numpy 数组 (H,W,B) float32</span><br><span class="line">	3) 在 out_dir 下以“镜像目录结构”保存为 .npy（例如 14H/14-1.npy 或 46H-2/46-1.npy）</span><br><span class="line">	4) 写出 --metadata 指定的 CSV，字段包括：</span><br><span class="line">		 - filename：样本在原始数据集中的规范路径（绝对路径），如 /.../6H-2/6-1</span><br><span class="line">		 - npy_filename：对应 .npy 在 out_dir 下的相对路径，如 6H-2/6-1.npy</span><br><span class="line">		 - Value_Raw, toxin_value, sample_name</span><br><span class="line">	5) 可选计算数据集通道均值/方差（--compute-stats），写入 stats.json</span><br><span class="line"></span><br><span class="line">续跑/容错：</span><br><span class="line">	- --resume：跳过已存在的 .npy，并合并已有的 CSV，支持从中断处继续。</span><br><span class="line">	- --start-index：从指定（Excel 清洗后）行号开始（1-based）。</span><br><span class="line">	- 磁盘满（ENOSPC）时，脚本会先安全落盘当前 CSV 再停止，释放空间后加 --resume 继续。</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">from __future__ import annotations</span><br><span class="line"></span><br><span class="line">import os</span><br><span class="line">import sys</span><br><span class="line">import csv</span><br><span class="line">import json</span><br><span class="line">import math</span><br><span class="line">import glob</span><br><span class="line">import argparse</span><br><span class="line">from typing import Optional, Tuple, List, Dict</span><br><span class="line"></span><br><span class="line">import numpy as np</span><br><span class="line">import pandas as pd</span><br><span class="line">import errno</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">CHUNK_SIZE = 40  # number of samples per &quot;H&quot; folder before rolling to &quot;-2&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def log(msg: str):</span><br><span class="line">	print(msg, flush=True)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def ensure_dir(path: str):</span><br><span class="line">	os.makedirs(path, exist_ok=True)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def parse_excel(excel_path: str) -&gt; pd.DataFrame:</span><br><span class="line">	&quot;&quot;&quot;Load the Excel and normalize the required columns.</span><br><span class="line"></span><br><span class="line">	We try to support a few possible header variants by case-insensitive matching and</span><br><span class="line">	fallback aliases. Required logical fields:</span><br><span class="line">	  - sample_name</span><br><span class="line">	  - area (Value_Raw)</span><br><span class="line">	  - toxic (toxin_value)</span><br><span class="line">	&quot;&quot;&quot;</span><br><span class="line">	df = pd.read_excel(excel_path)</span><br><span class="line">	# normalize column names for robust matching</span><br><span class="line">	col_map = &#123;c: str(c).strip() for c in df.columns&#125;</span><br><span class="line">	df = df.rename(columns=col_map)</span><br><span class="line">	lower_cols = &#123;c.lower(): c for c in df.columns&#125;</span><br><span class="line"></span><br><span class="line">	def pick(*candidates) -&gt; Optional[str]:</span><br><span class="line">		for cand in candidates:</span><br><span class="line">			key = cand.lower()</span><br><span class="line">			if key in lower_cols:</span><br><span class="line">				return lower_cols[key]</span><br><span class="line">		# fallback: substring contains</span><br><span class="line">		for c in df.columns:</span><br><span class="line">			lc = c.lower()</span><br><span class="line">			if any(k in lc for k in [cand.lower() for cand in candidates]):</span><br><span class="line">				return c</span><br><span class="line">		return None</span><br><span class="line"></span><br><span class="line">	col_sample = pick(&quot;Sample Name&quot;, &quot;Sample Name(filename)&quot;, &quot;filename&quot;, &quot;Sample&quot;, &quot;样本&quot;)</span><br><span class="line">	col_area = pick(&quot;Area&quot;, &quot;Area(value raw)&quot;, &quot;Value_Raw&quot;, &quot;value raw&quot;, &quot;面积&quot;)</span><br><span class="line">	col_toxic = pick(&quot;Toxic content&quot;, &quot;toxin_value&quot;, &quot;Toxic&quot;, &quot;毒素&quot;, &quot;毒性&quot;)</span><br><span class="line"></span><br><span class="line">	missing = [</span><br><span class="line">		name for name, val in [</span><br><span class="line">			(&quot;Sample Name&quot;, col_sample), (&quot;Area&quot;, col_area), (&quot;Toxic content&quot;, col_toxic)</span><br><span class="line">		] if val is None</span><br><span class="line">	]</span><br><span class="line">	if missing:</span><br><span class="line">		raise ValueError(f&quot;Excel missing required columns: &#123;missing&#125;. Found columns=&#123;list(df.columns)&#125;&quot;)</span><br><span class="line"></span><br><span class="line">	out = pd.DataFrame(&#123;</span><br><span class="line">		&quot;sample_name&quot;: df[col_sample].astype(str).str.strip(),</span><br><span class="line">		&quot;Value_Raw&quot;: pd.to_numeric(df[col_area], errors=&quot;coerce&quot;),</span><br><span class="line">		&quot;toxin_value&quot;: pd.to_numeric(df[col_toxic], errors=&quot;coerce&quot;),</span><br><span class="line">	&#125;)</span><br><span class="line">	# drop rows with missing numeric values</span><br><span class="line">	out = out.dropna(subset=[&quot;Value_Raw&quot;, &quot;toxin_value&quot;]).reset_index(drop=True)</span><br><span class="line">	return out</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def parse_hdr(hdr_path: str) -&gt; Dict[str, object]:</span><br><span class="line">	meta: Dict[str, object] = &#123;&#125;</span><br><span class="line">	with open(hdr_path, &quot;r&quot;, encoding=&quot;utf-8&quot;, errors=&quot;ignore&quot;) as f:</span><br><span class="line">		for raw in f:</span><br><span class="line">			line = raw.strip()</span><br><span class="line">			if not line or &quot;=&quot; not in line:</span><br><span class="line">				continue</span><br><span class="line">			k, v = [x.strip() for x in line.split(&quot;=&quot;, 1)]</span><br><span class="line">			kl = k.lower()</span><br><span class="line">			if v.startswith(&quot;&#123;&quot;) and v.endswith(&quot;&#125;&quot;):</span><br><span class="line">				v = v[1:-1].strip()</span><br><span class="line">			# try numeric</span><br><span class="line">			try:</span><br><span class="line">				if &quot;.&quot; in v:</span><br><span class="line">					vf = float(v)</span><br><span class="line">					if vf.is_integer():</span><br><span class="line">						vf = int(vf)</span><br><span class="line">					meta[kl] = vf</span><br><span class="line">				else:</span><br><span class="line">					meta[kl] = int(v)</span><br><span class="line">				continue</span><br><span class="line">			except Exception:</span><br><span class="line">				pass</span><br><span class="line">			meta[kl] = v</span><br><span class="line"></span><br><span class="line">	def get_num(key: str, default=None):</span><br><span class="line">		for cand in (key, key.replace(&quot; &quot;, &quot;&quot;)):</span><br><span class="line">			if cand in meta and isinstance(meta[cand], (int, float)):</span><br><span class="line">				return int(meta[cand])</span><br><span class="line">		return default</span><br><span class="line"></span><br><span class="line">	samples = get_num(&quot;samples&quot;)</span><br><span class="line">	lines = get_num(&quot;lines&quot;)</span><br><span class="line">	bands = get_num(&quot;bands&quot;)</span><br><span class="line">	interleave = str(meta.get(&quot;interleave&quot;, meta.get(&quot;interleave&quot;, &quot;bsq&quot;))).lower()</span><br><span class="line">	data_type = str(meta.get(&quot;data type&quot;, meta.get(&quot;datatype&quot;, &quot;4&quot;)))</span><br><span class="line">	return &#123;&quot;samples&quot;: samples, &quot;lines&quot;: lines, &quot;bands&quot;: bands, &quot;interleave&quot;: interleave, &quot;data type&quot;: data_type&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def read_spe(spe_path: str, meta: Dict[str, object]) -&gt; np.ndarray:</span><br><span class="line">	samples = int(meta[&quot;samples&quot;]) if meta[&quot;samples&quot;] is not None else None</span><br><span class="line">	lines = int(meta[&quot;lines&quot;]) if meta[&quot;lines&quot;] is not None else None</span><br><span class="line">	bands = int(meta[&quot;bands&quot;]) if meta[&quot;bands&quot;] is not None else None</span><br><span class="line">	if None in (samples, lines, bands):</span><br><span class="line">		raise ValueError(&quot;Missing samples/lines/bands in HDR metadata&quot;)</span><br><span class="line">	interleave = str(meta[&quot;interleave&quot;]).lower()</span><br><span class="line">	dtype_map = &#123;</span><br><span class="line">		&quot;1&quot;: np.uint8,</span><br><span class="line">		&quot;2&quot;: np.int16,</span><br><span class="line">		&quot;3&quot;: np.int32,</span><br><span class="line">		&quot;4&quot;: np.float32,</span><br><span class="line">		&quot;12&quot;: np.uint16,</span><br><span class="line">		&quot;13&quot;: np.uint32,</span><br><span class="line">	&#125;</span><br><span class="line">	dt = dtype_map.get(str(meta[&quot;data type&quot;]).strip(), np.float32)</span><br><span class="line"></span><br><span class="line">	arr = np.fromfile(spe_path, dtype=dt)</span><br><span class="line">	expected = lines * samples * bands</span><br><span class="line">	if arr.size &lt; expected:</span><br><span class="line">		raise ValueError(f&quot;SPE size too small: &#123;arr.size&#125; &lt; &#123;expected&#125;&quot;)</span><br><span class="line">	if arr.size &gt; expected:</span><br><span class="line">		arr = arr[:expected]</span><br><span class="line"></span><br><span class="line">	if interleave == &quot;bsq&quot;:</span><br><span class="line">		arr = arr.reshape((bands, lines, samples)).transpose(1, 2, 0)</span><br><span class="line">	elif interleave == &quot;bil&quot;:</span><br><span class="line">		arr = arr.reshape((lines, bands, samples)).transpose(0, 2, 1)</span><br><span class="line">	elif interleave == &quot;bip&quot;:</span><br><span class="line">		arr = arr.reshape((lines, samples, bands))</span><br><span class="line">	else:</span><br><span class="line">		raise ValueError(f&quot;Unknown interleave: &#123;interleave&#125;&quot;)</span><br><span class="line">	return arr.astype(np.float32, copy=False)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def _candidate_dirs(data_root: str, prefix: str, global_idx: Optional[int]) -&gt; List[str]:</span><br><span class="line">	&quot;&quot;&quot;Build ordered candidate directories for given prefix (e.g., &#x27;14&#x27;) and global index.</span><br><span class="line">	Handles: 14H, 14h, 14 H, 14H-2, 14h-2, 14H2</span><br><span class="line">	&quot;&quot;&quot;</span><br><span class="line">	cands: List[str] = []</span><br><span class="line">	# first include all dirs starting with prefix (robust):</span><br><span class="line">	try:</span><br><span class="line">		for d in os.listdir(data_root):</span><br><span class="line">			if d.lower().startswith(prefix.lower()):</span><br><span class="line">				cands.append(os.path.join(data_root, d))</span><br><span class="line">	except FileNotFoundError:</span><br><span class="line">		return []</span><br><span class="line"></span><br><span class="line">	# deterministic ones based on chunk</span><br><span class="line">	if global_idx is not None:</span><br><span class="line">		chunk = (global_idx - 1) // CHUNK_SIZE + 1</span><br><span class="line">		if chunk == 1:</span><br><span class="line">			cands.insert(0, os.path.join(data_root, f&quot;&#123;prefix&#125;H&quot;))</span><br><span class="line">			cands.insert(1, os.path.join(data_root, f&quot;&#123;prefix&#125;h&quot;))</span><br><span class="line">		else:</span><br><span class="line">			cands.insert(0, os.path.join(data_root, f&quot;&#123;prefix&#125;H-&#123;chunk&#125;&quot;))</span><br><span class="line">			cands.insert(1, os.path.join(data_root, f&quot;&#123;prefix&#125;h-&#123;chunk&#125;&quot;))</span><br><span class="line">			cands.insert(2, os.path.join(data_root, f&quot;&#123;prefix&#125;H&#123;chunk&#125;&quot;))</span><br><span class="line">	# remove duplicates, keep order</span><br><span class="line">	uniq = []</span><br><span class="line">	seen = set()</span><br><span class="line">	for p in cands:</span><br><span class="line">		if p not in seen:</span><br><span class="line">			uniq.append(p)</span><br><span class="line">			seen.add(p)</span><br><span class="line">	return uniq</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def find_envi_for_sample(data_root: str, sample_name: str) -&gt; Optional[Tuple[str, str, str]]:</span><br><span class="line">	&quot;&quot;&quot;Return (folder_rel, hdr_path, spe_path) if found, else None.</span><br><span class="line">	folder_rel is a relative folder like &#x27;14H&#x27; or &#x27;46H-2/46-1&#x27;. Final .npy path will be folder_rel + &#x27;.npy&#x27;</span><br><span class="line">	We compute local index inside chunked folder when sample_name has prefix-suffix pattern like &#x27;46-41&#x27;.</span><br><span class="line">	&quot;&quot;&quot;</span><br><span class="line">	name = sample_name.strip().replace(&quot;\\&quot;, &quot;/&quot;)</span><br><span class="line">	# extract prefix (before &#x27;-&#x27;) and suffix (after &#x27;-&#x27;) if possible</span><br><span class="line">	prefix = None</span><br><span class="line">	suffix_num: Optional[int] = None</span><br><span class="line">	if &quot;-&quot; in name:</span><br><span class="line">		parts = name.split(&quot;-&quot;, 1)</span><br><span class="line">		prefix = &#x27;&#x27;.join([ch for ch in parts[0] if ch.isdigit()]) or parts[0]</span><br><span class="line">		try:</span><br><span class="line">			suffix_num = int(&#x27;&#x27;.join([ch for ch in parts[1] if ch.isdigit()]))</span><br><span class="line">		except Exception:</span><br><span class="line">			suffix_num = None</span><br><span class="line">	else:</span><br><span class="line">		# try pattern like &#x27;14H/14-1&#x27; -&gt; take the last segment</span><br><span class="line">		base = os.path.basename(name)</span><br><span class="line">		if &quot;-&quot; in base:</span><br><span class="line">			return find_envi_for_sample(data_root, base)</span><br><span class="line">		# fallback: take leading digits as prefix</span><br><span class="line">		digits = &#x27;&#x27;.join([ch for ch in base if ch.isdigit()])</span><br><span class="line">		prefix = digits if digits else base</span><br><span class="line"></span><br><span class="line">	candidate_dirs = _candidate_dirs(data_root, prefix, suffix_num)</span><br><span class="line">	local_idx = ((suffix_num - 1) % CHUNK_SIZE + 1) if suffix_num is not None else None</span><br><span class="line"></span><br><span class="line">	# search directories</span><br><span class="line">	for d in candidate_dirs:</span><br><span class="line">		if not os.path.isdir(d):</span><br><span class="line">			continue</span><br><span class="line">		# try direct files in dir</span><br><span class="line">		direct_hdr = glob.glob(os.path.join(d, &quot;*.hdr&quot;))</span><br><span class="line">		direct_spe = glob.glob(os.path.join(d, &quot;*.spe&quot;))</span><br><span class="line">		# if there are direct files, try to pick ones containing the local/global index</span><br><span class="line">		if direct_hdr and direct_spe:</span><br><span class="line">			def _pick_match(paths: List[str]) -&gt; Optional[str]:</span><br><span class="line">				# prefer containing &#x27;-&lt;local_idx&gt;&#x27; or full sample_name</span><br><span class="line">				lc = str(local_idx) if local_idx is not None else None</span><br><span class="line">				sn = name.lower()</span><br><span class="line">				for p in paths:</span><br><span class="line">					b = os.path.basename(p).lower()</span><br><span class="line">					if lc and (f&quot;-&#123;lc&#125;.&quot; in b or f&quot;-&#123;lc&#125;_&quot; in b or b.startswith(f&quot;&#123;prefix.lower()&#125;-&#123;lc&#125;&quot;)):</span><br><span class="line">						return p</span><br><span class="line">					if prefix and b.startswith(prefix.lower()) and (lc is None or lc in b):</span><br><span class="line">						return p</span><br><span class="line">					if sn in b:</span><br><span class="line">						return p</span><br><span class="line">				return None</span><br><span class="line">			hdr = _pick_match(direct_hdr) or direct_hdr[0]</span><br><span class="line">			spe = _pick_match(direct_spe) or direct_spe[0]</span><br><span class="line">			if hdr and spe:</span><br><span class="line">				# folder_rel is d relative to data_root</span><br><span class="line">				folder_rel = os.path.relpath(d, data_root)</span><br><span class="line">				return folder_rel, hdr, spe</span><br><span class="line"></span><br><span class="line">		# try subfolders like &#x27;46-1&#x27;, &#x27;46-2&#x27;, ... and find files inside</span><br><span class="line">		try:</span><br><span class="line">			for sub in os.listdir(d):</span><br><span class="line">				subp = os.path.join(d, sub)</span><br><span class="line">				if not os.path.isdir(subp):</span><br><span class="line">					continue</span><br><span class="line">				# match subfolder by local index</span><br><span class="line">				if local_idx is not None:</span><br><span class="line">					if not (sub.lower() == f&quot;&#123;prefix.lower()&#125;-&#123;local_idx&#125;&quot; or sub.lower() == f&quot;&#123;prefix.lower()&#125;&#123;local_idx&#125;&quot; or sub.lower().startswith(f&quot;&#123;prefix.lower()&#125;-&#123;local_idx&#125;&quot;)):</span><br><span class="line">						# not a direct match; still allow scanning but deprioritized</span><br><span class="line">						pass</span><br><span class="line">				hdrs = glob.glob(os.path.join(subp, &quot;*.hdr&quot;))</span><br><span class="line">				spes = glob.glob(os.path.join(subp, &quot;*.spe&quot;))</span><br><span class="line">				if hdrs and spes:</span><br><span class="line">					# pick first or matching</span><br><span class="line">					hdr = hdrs[0]</span><br><span class="line">					spe = spes[0]</span><br><span class="line">					folder_rel = os.path.relpath(subp, data_root)</span><br><span class="line">					return folder_rel, hdr, spe</span><br><span class="line">		except Exception:</span><br><span class="line">			pass</span><br><span class="line"></span><br><span class="line">	# Final fallback: recursive glob anywhere containing digits from name</span><br><span class="line">	nums = [tok for tok in name.replace(&#x27;-&#x27;, &#x27; &#x27;).split() if any(c.isdigit() for c in tok)]</span><br><span class="line">	hdrs = glob.glob(os.path.join(data_root, &quot;**&quot;, &quot;*.hdr&quot;), recursive=True)</span><br><span class="line">	spes = glob.glob(os.path.join(data_root, &quot;**&quot;, &quot;*.spe&quot;), recursive=True)</span><br><span class="line">	def match_any(paths: List[str]) -&gt; Optional[str]:</span><br><span class="line">		for p in paths:</span><br><span class="line">			b = os.path.basename(p).lower()</span><br><span class="line">			if any(n.lower() in b for n in nums):</span><br><span class="line">				return p</span><br><span class="line">		return None</span><br><span class="line">	hdr = match_any(hdrs)</span><br><span class="line">	spe = match_any(spes)</span><br><span class="line">	if hdr and spe:</span><br><span class="line">		folder_rel = os.path.relpath(os.path.dirname(hdr), data_root)</span><br><span class="line">		return folder_rel, hdr, spe</span><br><span class="line"></span><br><span class="line">	return None</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def canonical_rel_path(sample_name: str) -&gt; Optional[str]:</span><br><span class="line">	&quot;&quot;&quot;Compute canonical relative dataset path like &#x27;6H-2/6-1&#x27; from &#x27;6-41&#x27;.</span><br><span class="line">	Returns None if cannot parse numbers.</span><br><span class="line">	&quot;&quot;&quot;</span><br><span class="line">	name = sample_name.strip()</span><br><span class="line">	if &quot;-&quot; not in name:</span><br><span class="line">		return None</span><br><span class="line">	p0, p1 = name.split(&quot;-&quot;, 1)</span><br><span class="line">	prefix_digits = &#x27;&#x27;.join([ch for ch in p0 if ch.isdigit()]) or p0</span><br><span class="line">	try:</span><br><span class="line">		global_idx = int(&#x27;&#x27;.join([ch for ch in p1 if ch.isdigit()]))</span><br><span class="line">	except Exception:</span><br><span class="line">		return None</span><br><span class="line">	chunk = (global_idx - 1) // CHUNK_SIZE + 1</span><br><span class="line">	local_idx = ((global_idx - 1) % CHUNK_SIZE) + 1</span><br><span class="line">	head = f&quot;&#123;prefix_digits&#125;H&quot; if chunk == 1 else f&quot;&#123;prefix_digits&#125;H-&#123;chunk&#125;&quot;</span><br><span class="line">	leaf = f&quot;&#123;prefix_digits&#125;-&#123;local_idx&#125;&quot;</span><br><span class="line">	return os.path.join(head, leaf)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def compute_stats_over_saved(npy_paths: List[str]) -&gt; Tuple[List[float], List[float]]:</span><br><span class="line">	&quot;&quot;&quot;Compute per-channel mean/std across a list of saved .npy files.</span><br><span class="line">	Assumes all arrays share the same last-dimension (bands). If shapes differ in H/W,</span><br><span class="line">	aggregates across all pixels.</span><br><span class="line">	&quot;&quot;&quot;</span><br><span class="line">	if not npy_paths:</span><br><span class="line">		return [], []</span><br><span class="line">	# determine bands from first file</span><br><span class="line">	first = np.load(npy_paths[0], mmap_mode=&#x27;r&#x27;)</span><br><span class="line">	if first.ndim == 2:</span><br><span class="line">		# upgrade grayscale to one-band</span><br><span class="line">		bands = 1</span><br><span class="line">	else:</span><br><span class="line">		bands = int(first.shape[2])</span><br><span class="line">	total = np.zeros((bands,), dtype=np.float64)</span><br><span class="line">	total_sq = np.zeros((bands,), dtype=np.float64)</span><br><span class="line">	n_pix = 0</span><br><span class="line"></span><br><span class="line">	for p in npy_paths:</span><br><span class="line">		arr = np.load(p)</span><br><span class="line">		if arr.ndim == 2:</span><br><span class="line">			arr = arr[:, :, None]</span><br><span class="line">		h, w, b = arr.shape</span><br><span class="line">		if b != bands:</span><br><span class="line">			# skip inconsistent band count</span><br><span class="line">			continue</span><br><span class="line">		flat = arr.reshape(-1, b).astype(np.float64)</span><br><span class="line">		total += flat.sum(axis=0)</span><br><span class="line">		total_sq += (flat ** 2).sum(axis=0)</span><br><span class="line">		n_pix += flat.shape[0]</span><br><span class="line"></span><br><span class="line">	if n_pix == 0:</span><br><span class="line">		return [], []</span><br><span class="line">	mean = (total / n_pix)</span><br><span class="line">	var = total_sq / n_pix - mean ** 2</span><br><span class="line">	std = np.sqrt(np.maximum(var, 1e-12))</span><br><span class="line">	return mean.tolist(), std.tolist()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def main():</span><br><span class="line">	ap = argparse.ArgumentParser(description=&quot;Prepare .npy and metadata from ENVI dataset&quot;)</span><br><span class="line">	ap.add_argument(&quot;--excel&quot;, required=True, help=&quot;Path to the source Excel, e.g., 20251015-数据统计-是这个.xlsx&quot;)</span><br><span class="line">	ap.add_argument(&quot;--data_root&quot;, required=True, help=&quot;Root folder of hyperspectral ENVI data (contains *H, *H-2 folders)&quot;)</span><br><span class="line">	ap.add_argument(&quot;--out_dir&quot;, required=True, help=&quot;Output folder to write .npy files and (optionally) stats.json&quot;)</span><br><span class="line">	ap.add_argument(&quot;--metadata&quot;, required=True, help=&quot;Path to write new_metadata.csv&quot;)</span><br><span class="line">	ap.add_argument(&quot;--recursive&quot;, action=&quot;store_true&quot;, help=&quot;Unused flag (kept for CLI compatibility)&quot;)</span><br><span class="line">	ap.add_argument(&quot;--limit&quot;, type=int, default=0, help=&quot;Process only the first N rows for a quick dry run&quot;)</span><br><span class="line">	ap.add_argument(&quot;--compute-stats&quot;, action=&quot;store_true&quot;, help=&quot;Also compute mean/std over saved .npy and write stats.json&quot;)</span><br><span class="line">	ap.add_argument(&quot;--resume&quot;, action=&quot;store_true&quot;, help=&quot;Skip samples whose target .npy already exists; merge with existing metadata if present&quot;)</span><br><span class="line">	ap.add_argument(&quot;--start-index&quot;, type=int, default=1, help=&quot;1-based row index in Excel (after cleaning) to start from, e.g., 213&quot;)</span><br><span class="line">	args = ap.parse_args()</span><br><span class="line"></span><br><span class="line">	excel = os.path.normpath(args.excel)</span><br><span class="line">	data_root = os.path.normpath(args.data_root)</span><br><span class="line">	out_dir = os.path.normpath(args.out_dir)</span><br><span class="line">	metadata_csv = os.path.normpath(args.metadata)</span><br><span class="line">	ensure_dir(out_dir)</span><br><span class="line">	ensure_dir(os.path.dirname(metadata_csv))</span><br><span class="line"></span><br><span class="line">	log(f&quot;Excel: &#123;excel&#125;&quot;)</span><br><span class="line">	log(f&quot;Data root: &#123;data_root&#125;&quot;)</span><br><span class="line">	log(f&quot;Out dir: &#123;out_dir&#125;&quot;)</span><br><span class="line">	log(f&quot;Metadata CSV: &#123;metadata_csv&#125;&quot;)</span><br><span class="line"></span><br><span class="line">	df = parse_excel(excel)</span><br><span class="line">	# Apply start-index (1-based)</span><br><span class="line">	start_idx = max(1, int(args.start_index)) if args.start_index else 1</span><br><span class="line">	if start_idx &gt; 1:</span><br><span class="line">		if start_idx &gt; len(df):</span><br><span class="line">			log(f&quot;start-index &#123;start_idx&#125; beyond dataset length &#123;len(df)&#125;; nothing to do&quot;)</span><br><span class="line">			# still flush existing to ensure CSV header exists</span><br><span class="line">			# and exit early</span><br><span class="line">			# create empty CSV if needed</span><br><span class="line">			existing_only = []</span><br><span class="line">			keys = [&quot;filename&quot;, &quot;npy_filename&quot;, &quot;Value_Raw&quot;, &quot;toxin_value&quot;, &quot;sample_name&quot;]</span><br><span class="line">			if not os.path.isfile(metadata_csv):</span><br><span class="line">				with open(metadata_csv, &quot;w&quot;, newline=&quot;&quot;, encoding=&quot;utf-8-sig&quot;) as fw:</span><br><span class="line">					writer = csv.DictWriter(fw, fieldnames=keys)</span><br><span class="line">					writer.writeheader()</span><br><span class="line">			return</span><br><span class="line">		log(f&quot;Starting from row &#123;start_idx&#125;; skipping first &#123;start_idx-1&#125; rows&quot;)</span><br><span class="line">		df = df.iloc[start_idx - 1 : ].copy()</span><br><span class="line">	if args.limit and args.limit &gt; 0:</span><br><span class="line">		df = df.iloc[: args.limit].copy()</span><br><span class="line">		log(f&quot;Limiting to first &#123;len(df)&#125; rows for dry run&quot;)</span><br><span class="line"></span><br><span class="line">	# Load existing metadata (for resume) if any</span><br><span class="line">	existing_records: List[Dict[str, str]] = []</span><br><span class="line">	existing_npy: set = set()</span><br><span class="line">	if os.path.isfile(metadata_csv):</span><br><span class="line">		try:</span><br><span class="line">			with open(metadata_csv, &quot;r&quot;, encoding=&quot;utf-8-sig&quot;) as fr:</span><br><span class="line">				reader = csv.DictReader(fr)</span><br><span class="line">				for r in reader:</span><br><span class="line">					existing_records.append(r)</span><br><span class="line">					if &quot;npy_filename&quot; in r and r[&quot;npy_filename&quot;]:</span><br><span class="line">						existing_npy.add(r[&quot;npy_filename&quot;].replace(&quot;\\&quot;, &quot;/&quot;))</span><br><span class="line">			log(f&quot;Loaded existing metadata rows: &#123;len(existing_records)&#125;&quot;)</span><br><span class="line">		except Exception as e:</span><br><span class="line">			log(f&quot;Warning: failed to load existing metadata for resume: &#123;e&#125;&quot;)</span><br><span class="line"></span><br><span class="line">	records = []  # new records in this run</span><br><span class="line">	saved_paths = []  # for stats</span><br><span class="line">	errors = []</span><br><span class="line">	flush_interval = 100</span><br><span class="line"></span><br><span class="line">	def flush_metadata():</span><br><span class="line">		# Merge existing + new and write de-duplicated by npy_filename</span><br><span class="line">		if not (existing_records or records):</span><br><span class="line">			return</span><br><span class="line">		merged = []</span><br><span class="line">		seen = set()</span><br><span class="line">		for r in existing_records + records:</span><br><span class="line">			key = (r.get(&quot;npy_filename&quot;) or r.get(&quot;filename&quot;) or &quot;&quot;).replace(&quot;\\&quot;, &quot;/&quot;)</span><br><span class="line">			if key and key not in seen:</span><br><span class="line">				merged.append(r)</span><br><span class="line">				seen.add(key)</span><br><span class="line">		keys = [&quot;filename&quot;, &quot;npy_filename&quot;, &quot;Value_Raw&quot;, &quot;toxin_value&quot;, &quot;sample_name&quot;]</span><br><span class="line">		try:</span><br><span class="line">			with open(metadata_csv, &quot;w&quot;, newline=&quot;&quot;, encoding=&quot;utf-8-sig&quot;) as fw:</span><br><span class="line">				writer = csv.DictWriter(fw, fieldnames=keys)</span><br><span class="line">				writer.writeheader()</span><br><span class="line">				writer.writerows(merged)</span><br><span class="line">			log(f&quot;Flushed metadata: &#123;len(merged)&#125; rows&quot;)</span><br><span class="line">		except Exception as e:</span><br><span class="line">			log(f&quot;Warning: failed to flush metadata: &#123;e&#125;&quot;)</span><br><span class="line"></span><br><span class="line">	for i, row in df.iterrows():</span><br><span class="line">		sample_name = str(row[&quot;sample_name&quot;]).strip()</span><br><span class="line">		value_raw = float(row[&quot;Value_Raw&quot;]) if pd.notna(row[&quot;Value_Raw&quot;]) else None</span><br><span class="line">		toxin_value = float(row[&quot;toxin_value&quot;]) if pd.notna(row[&quot;toxin_value&quot;]) else None</span><br><span class="line">		if value_raw is None or toxin_value is None:</span><br><span class="line">			errors.append((sample_name, &quot;missing_value&quot;, None))</span><br><span class="line">			continue</span><br><span class="line"></span><br><span class="line">		# We first compute the canonical path for consistent metadata &amp; npy placement</span><br><span class="line">		canon_rel = canonical_rel_path(sample_name)</span><br><span class="line">		# If canonical path is computable and npy already exists (resume), rebuild metadata row only</span><br><span class="line">		if canon_rel is not None:</span><br><span class="line">			npy_rel = f&quot;&#123;canon_rel&#125;.npy&quot;</span><br><span class="line">			dataset_rel = canon_rel</span><br><span class="line">			out_path = os.path.join(out_dir, npy_rel)</span><br><span class="line">			if args.resume and os.path.isfile(out_path):</span><br><span class="line">				records.append(&#123;</span><br><span class="line">					&quot;filename&quot;: os.path.join(data_root, dataset_rel).replace(&quot;\\&quot;, &quot;/&quot;),</span><br><span class="line">					&quot;npy_filename&quot;: npy_rel.replace(&quot;\\&quot;, &quot;/&quot;),</span><br><span class="line">					&quot;Value_Raw&quot;: value_raw,</span><br><span class="line">					&quot;toxin_value&quot;: toxin_value,</span><br><span class="line">					&quot;sample_name&quot;: sample_name,</span><br><span class="line">				&#125;)</span><br><span class="line">				if (i + 1) % 20 == 0:</span><br><span class="line">					log(f&quot;Processed &#123;i + 1&#125; / &#123;len(df)&#125;&quot;)</span><br><span class="line">				if (len(records) % flush_interval) == 0 and len(records) &gt; 0:</span><br><span class="line">					flush_metadata()</span><br><span class="line">				continue</span><br><span class="line"></span><br><span class="line">		# We still locate actual hdr/spe to read data</span><br><span class="line">		found = find_envi_for_sample(data_root, sample_name)</span><br><span class="line">		if not found:</span><br><span class="line">			errors.append((sample_name, &quot;not_found&quot;, None))</span><br><span class="line">			continue</span><br><span class="line">		folder_rel, hdr_p, spe_p = found</span><br><span class="line"></span><br><span class="line">		try:</span><br><span class="line">			meta = parse_hdr(hdr_p)</span><br><span class="line">			arr = read_spe(spe_p, meta)  # (H,W,B), float32</span><br><span class="line">		except Exception as e:</span><br><span class="line">			errors.append((sample_name, &quot;read_error&quot;, str(e)))</span><br><span class="line">			continue</span><br><span class="line"></span><br><span class="line">		# Compose canonical relative filename for npy: e.g., &#x27;6H-2/6-1.npy&#x27;</span><br><span class="line">		if canon_rel is None:</span><br><span class="line">			# fallback to discovered folder and stem</span><br><span class="line">			leaf = os.path.basename(folder_rel)</span><br><span class="line">			base_name = leaf if (&#x27;-&#x27; in leaf and any(c.isdigit() for c in leaf)) else os.path.splitext(os.path.basename(spe_p))[0]</span><br><span class="line">			npy_rel = os.path.join(folder_rel, f&quot;&#123;base_name&#125;.npy&quot;)</span><br><span class="line">			dataset_rel = os.path.join(folder_rel, base_name)</span><br><span class="line">		else:</span><br><span class="line">			npy_rel = f&quot;&#123;canon_rel&#125;.npy&quot;</span><br><span class="line">			dataset_rel = canon_rel</span><br><span class="line">		out_path = os.path.join(out_dir, npy_rel)</span><br><span class="line"></span><br><span class="line">		# Resume: if target npy exists and --resume, skip recompute and just ensure metadata will have the row</span><br><span class="line">		if args.resume and os.path.isfile(out_path):</span><br><span class="line">			pass  # we will still add metadata row if missing below</span><br><span class="line">		else:</span><br><span class="line">			# Make directory and save, with ENOSPC handling</span><br><span class="line">			try:</span><br><span class="line">				ensure_dir(os.path.dirname(out_path))</span><br><span class="line">				np.save(out_path, arr.astype(np.float32, copy=False))</span><br><span class="line">				saved_paths.append(out_path)</span><br><span class="line">			except OSError as e:</span><br><span class="line">				if isinstance(e, OSError) and e.errno == errno.ENOSPC:</span><br><span class="line">					log(f&quot;Disk full when saving &#123;out_path&#125;. Stopping further writes; you can free space and rerun with --resume.&quot;)</span><br><span class="line">					# Flush metadata collected so far, then break out of processing loop</span><br><span class="line">					flush_metadata()</span><br><span class="line">					break</span><br><span class="line">				else:</span><br><span class="line">					errors.append((sample_name, &quot;save_error&quot;, str(e)))</span><br><span class="line">					continue</span><br><span class="line"></span><br><span class="line">		# Store metadata:</span><br><span class="line">		# - filename: absolute canonical dataset path under data_root (folder), e.g., &#x27;/.../6H-2/6-1&#x27;</span><br><span class="line">		# - npy_filename: path of saved npy relative to out_dir, e.g., &#x27;6H-2/6-1.npy&#x27;</span><br><span class="line">		records.append(&#123;</span><br><span class="line">			&quot;filename&quot;: os.path.join(data_root, dataset_rel).replace(&quot;\\&quot;, &quot;/&quot;),</span><br><span class="line">			&quot;npy_filename&quot;: npy_rel.replace(&quot;\\&quot;, &quot;/&quot;),</span><br><span class="line">			&quot;Value_Raw&quot;: value_raw,</span><br><span class="line">			&quot;toxin_value&quot;: toxin_value,</span><br><span class="line">			&quot;sample_name&quot;: sample_name,</span><br><span class="line">		&#125;)</span><br><span class="line"></span><br><span class="line">		if (i + 1) % 20 == 0:</span><br><span class="line">			log(f&quot;Processed &#123;i + 1&#125; / &#123;len(df)&#125;&quot;)</span><br><span class="line">		# periodic flush to not lose progress</span><br><span class="line">		if (len(records) % flush_interval) == 0 and len(records) &gt; 0:</span><br><span class="line">			flush_metadata()</span><br><span class="line"></span><br><span class="line">	# Write metadata CSV</span><br><span class="line">	# Final flush: merge and write all (existing + new)</span><br><span class="line">	flush_metadata()</span><br><span class="line"></span><br><span class="line">	# Write errors log if any</span><br><span class="line">	if errors:</span><br><span class="line">		err_path = os.path.join(out_dir, &quot;prepare_errors.csv&quot;)</span><br><span class="line">		with open(err_path, &quot;w&quot;, newline=&quot;&quot;, encoding=&quot;utf-8-sig&quot;) as fw:</span><br><span class="line">			w = csv.writer(fw)</span><br><span class="line">			w.writerow([&quot;sample_name&quot;, &quot;error_type&quot;, &quot;detail&quot;])</span><br><span class="line">			w.writerows(errors)</span><br><span class="line">		log(f&quot;Logged &#123;len(errors)&#125; issues -&gt; &#123;err_path&#125;&quot;)</span><br><span class="line"></span><br><span class="line">	# Optional stats</span><br><span class="line">	if args.compute_stats and records:</span><br><span class="line">		mean, std = compute_stats_over_saved([os.path.join(out_dir, r[&quot;npy_filename&quot;]) for r in records])</span><br><span class="line">		stats = &#123;&quot;mean&quot;: mean, &quot;std&quot;: std&#125;</span><br><span class="line">		stats_path = os.path.join(out_dir, &quot;stats.json&quot;)</span><br><span class="line">		with open(stats_path, &quot;w&quot;, encoding=&quot;utf-8&quot;) as fw:</span><br><span class="line">			json.dump(stats, fw)</span><br><span class="line">		log(f&quot;Wrote stats -&gt; &#123;stats_path&#125;&quot;)</span><br><span class="line"></span><br><span class="line">	log(&quot;Done.&quot;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line">	try:</span><br><span class="line">		main()</span><br><span class="line">	except KeyboardInterrupt:</span><br><span class="line">		log(&quot;Interrupted.&quot;)</span><br><span class="line">		sys.exit(130)</span><br><span class="line">	except Exception as e:</span><br><span class="line">		log(f&quot;Fatal error: &#123;e&#125;&quot;)</span><br><span class="line">		sys.exit(1)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
</div><div class="post-end"><div class="post-prev"><a href="/2025/10/30/2025-10-28/" title="上一篇文章"><i class="fa-solid fa-chevron-left fa-lg"></i></a></div><div class="post-next"><a href="/2025/10/13/2025-10-13/" title="下一篇文章"><i class="fa-solid fa-chevron-right fa-lg"></i></a></div></div></article><div class="comment" id="comment"><script src="https://giscus.app/client.js" data-repo="SchwertLin/SwertLin_Blog_Comment" data-repo-id="R_kgDONXjrCQ" data-category="Announcements" data-category-id="DIC_kwDONXjrCc4Cky9X" data-mapping="pathname" data-strict="0" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="bottom" data-theme="preferred_color_scheme" data-lang="zh-CN" crossorigin="anonymous" async="async"></script></div><div id="post-toc"><aside class="toc-aside"><div class="toc-title"><span><i class="fa-solid fa-paw"></i>目录</span></div><div class="toc-container" id="toc-body"></div></aside><div class="toc-blank" onclick="tocToggle()"></div></div><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  }
});
MathJax.Hub.Queue(function() {
  var all = MathJax.Hub.getAllJax(), i;
  for(i=0; i < all.length; i += 1) {
    all[i].SourceElement().parentNode.className += ' has-jax';
  }
});
</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.8/MathJax.js?config=TeX-AMS-MML_HTMLorMML" async="async"></script></div></div><div id="tool-bar"><div id="tool-bar-main"><div id="tool-toggle" onclick="toolToggle()" title="设置"><i class="fa-solid fa-gear"></i></div><div id="toc-toggle" onclick="tocToggle()" title="目录"><i class="fa-solid fa-list-ul"></i></div><div id="go-to-comment" onclick="gotoComment()" title="评论"><i class="fa-regular fa-message fa-flip-horizontal"></i></div><div id="back-to-top" onclick="scrollToTop()" title="返回顶部"><i class="fa-solid fa-chevron-up"></i></div></div><div id="tool-bar-more" style="display: none;"><div id="darkmode-switch" onclick="darkmodeSwitch()" title="深色模式"><i class="fa-solid fa-circle-half-stroke"></i></div><div id="font-size-increase" onclick="fontSizeIncrease()" title="放大字体"><i class="fa-solid fa-plus"></i></div><div id="font-size-decrease" onclick="fontSizeDecrease()" title="缩小字体"><i class="fa-solid fa-minus"></i></div></div></div><div id="search-panel"><div class="search-container"><div class="search-head"><div class="search-title"><span><i class="fa-solid fa-paw"></i>搜索</span></div><div class="search-close-btn" onclick="toggleSearchWindow()"><i class="fa-regular fa-circle-xmark"></i></div></div><div class="search-box"><i class="fa-solid fa-magnifying-glass"></i><input id="search-input" type="text" placeholder="请输入需要搜索的内容……" value=""/></div><div class="search-body"><div id="search-count">匹配结果数: </div><div id="search-result"></div><div id="search-result-empty">未搜索到匹配的文章。</div></div></div></div><footer><div class="footer-content"><div class="copyright-info"><i class="fa-regular fa-copyright fa-xs"></i><span>2022 - 2025 </span><a href="/about">Schwertlilien</a><i class="fa-solid fa-cat fa-sm"></i><span>Powered by </span><a href="https://hexo.io/" target="_blank">Hexo</a><span> &amp; </span><a href="https://github.com/chanwj/hexo-theme-meow" target="_blank" title="v2.1.0">Theme Meow</a></div><div class="pageview-site"><span id="busuanzi_container_site_pv">总访问量 : <span id="busuanzi_value_site_pv"><i class="fa-solid fa-spinner"></i></span></span><span id="busuanzi_container_site_uv">总访客数 : <span id="busuanzi_value_site_uv"><i class="fa-solid fa-spinner"></i></span></span></div></div></footer>
<script>const GLOBAL_CONFIG = {
  comment: { theme: 'preferred_color_scheme'}
}
</script>
<script src="/js/third-party/darkmode.js"></script>
<script>var options = {
  dark: '/css/darkmode.css',
  startAt: '24:00',
  endAt: '06:00',
  checkSystemScheme: 'false',
  saveOnToggle: 'true'
};
var darkMode = new DarkMode(options);
// change comment theme synchronously 同步修改评论区主题
if (darkMode.getMode() == "dark" && (true || true)) {
  if (document.getElementById('comment')) {
    document.getElementById('comment').getElementsByTagName('script')[0].setAttribute('data-theme', 'noborder_dark');
  }
}
</script><script>if (localStorage.getItem('font-size')) {
  document.querySelector('.post-content').style.fontSize = localStorage.getItem('font-size') + 'px';
}
</script>
<script src="/js/theme/tool-bar.js"></script>


<script src="/js/theme/menu.js"></script>


<script src="/js/third-party/clipboard.min.js"></script>


<script src="/js/theme/copy.js"></script>
<script>copyCode();
</script>
<script src="/js/jquery-3.7.1.min.js"></script>


<script src="/js/theme/search.js"></script>
<script>searchFunc('/search.xml', 'search-input', 'search-result');
</script></body></html>