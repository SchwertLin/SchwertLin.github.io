<!DOCTYPE html><html lang="zh-CN"><head><meta charset="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta name="author" content="Schwertlilien"/><meta name="keyword"/><meta name="description" content="感觉今天去听华为的会呢，引发了我自己的一些思考。 发现我自己对待未来的规划还是做的太少，我应该更多的思考这方面的事情了。 比如，或许我的目标是在今年年底写完一篇论文，最好是构思好下一个工作要做什么，这样就可以按部就班的去做了。然后考虑明年或者今年年底可以实习。   研究的目标：解决图片中不同类(不同菜品)的边界重叠&#x2F;混合&#x2F;覆盖的问题。 目前的背景：（也就是存在的困境不止一个challenge）">
<meta property="og:type" content="article">
<meta property="og:title" content="Sat Oct 11 2025 00:00:00 GMT+0800 (中國標準時間)">
<meta property="og:url" content="http://example.com/2025/10/11/2025-10-11/index.html">
<meta property="og:site_name" content="Schwertlilien">
<meta property="og:description" content="感觉今天去听华为的会呢，引发了我自己的一些思考。 发现我自己对待未来的规划还是做的太少，我应该更多的思考这方面的事情了。 比如，或许我的目标是在今年年底写完一篇论文，最好是构思好下一个工作要做什么，这样就可以按部就班的去做了。然后考虑明年或者今年年底可以实习。   研究的目标：解决图片中不同类(不同菜品)的边界重叠&#x2F;混合&#x2F;覆盖的问题。 目前的背景：（也就是存在的困境不止一个challenge）">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://raw.githubusercontent.com/SchwertLin/Pic/main/imgresize%2Cm_lfit%2Climit_1%2Ch_1080.png">
<meta property="og:image" content="https://raw.githubusercontent.com/SchwertLin/Pic/main/imgimage-20251013141433628.png">
<meta property="og:image" content="https://raw.githubusercontent.com/SchwertLin/Pic/main/imgimage-20251013141442720.png">
<meta property="og:image" content="https://raw.githubusercontent.com/SchwertLin/Pic/main/imgb7b1d8b2b45b41a4b4c98b18cddc1b51.jpeg">
<meta property="og:image" content="https://raw.githubusercontent.com/SchwertLin/Pic/main/img600_600_webapp.jpg">
<meta property="article:published_time" content="2025-10-11T06:17:11.000Z">
<meta property="article:modified_time" content="2025-10-22T10:00:08.350Z">
<meta property="article:author" content="Schwertlilien">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://raw.githubusercontent.com/SchwertLin/Pic/main/imgresize%2Cm_lfit%2Climit_1%2Ch_1080.png"><title>Sat Oct 11 2025 00:00:00 GMT+0800 (中國標準時間) - Schwertlilien - -----personal blog-----</title><link rel="shortcut icon" href="/img/site-icon.png">
<link rel="stylesheet" href="/css/style.css" id="dm-light">


<link rel="stylesheet" href="https://cdn.bootcdn.net/ajax/libs/font-awesome/6.4.2/css/all.min.css">

<script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script>
<meta name="generator" content="Hexo 7.3.0"></head><body><header><div class="top-nav" ondblclick="scrollToTop()"><div class="nav-info"><div class="nav-icon"><img id="nav-icon" src="/img/site-icon.png"/></div><div class="nav-title"><a id="nav-title" href="/" title="主页">Schwertlilien</a></div></div><div class="nav-ribbon"><div class="top-menu-expanded"><a class="top-menu-item" href="/archives"><span>归档</span></a><a class="top-menu-item" href="/categories"><span>分类</span></a><a class="top-menu-item" href="/tags"><span>标签</span></a><a class="top-menu-item" href="/about"><span>关于</span></a></div><div class="top-search" onclick="toggleSearchWindow()"><div id="top-search-btn" title="搜索"><i class="icon fa-solid fa-magnifying-glass"></i><span>搜索</span></div></div><div id="top-menu-btn" onclick="openTopMenu()" title="打开菜单"><i class="fa-solid fa-bars fa-lg"></i></div></div></div></header><div id="top-menu-hidden"><div class="menu-hidden-content"><div class="menu-hidden-nav"><a class="menu-hidden-item" href="/archives"><i class="fa-solid fa-box-archive fa-sm"></i><span>归档</span></a><a class="menu-hidden-item" href="/categories"><i class="fa-regular fa-folder-open fa-sm"></i><span>分类</span></a><a class="menu-hidden-item" href="/tags"><i class="fa-solid fa-tags fa-sm"></i><span>标签</span></a><a class="menu-hidden-item" href="/about"><i class="fa-solid fa-paw fa-sm"></i><span>关于</span></a></div></div><div class="menu-hidden-blank" onclick="closeTopMenu()"></div></div>
<div class="blog-info"><div class="blog-pic"><img id="blog-pic" src="/img/site-icon.png"/></div><div class="blog-title"><i class="fa-solid fa-paw fa-2xs fa-rotate-by"></i><span>Schwertlilien</span><i class="fa-solid fa-paw fa-2xs fa-rotate-by"></i></div><div class="blog-desc">As a recoder: notes and ideas.</div></div><div class="main"><div class="main-content"><article class="post"><div class="post-title"><h1><i class="fa-solid fa-paw"></i>Sat Oct 11 2025 00:00:00 GMT+0800 (中國標準時間)</h1></div><div class="post-info"><div class="post-info-first-line"><div class="post-date"><i class="icon fa-regular fa-calendar-plus" title="发布日期"></i><time class="publish-time">2025-10-11</time><i class="icon fa-regular fa-calendar-check" title="更新日期"></i><time class="update-time">2025-10-22</time></div>

</div><div class="post-info-second-line"><div class="post-copyright"><i class="icon fa-brands fa-creative-commons" title="版权声明"></i><span>版权声明: </span><a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-nd/4.0/deed.zh-hans" title="CC BY-NC-ND 4.0">署名-非商业性使用-禁止演绎 4.0</a></div>
<div class="post-word-count"><i class="icon fa-solid fa-pen-to-square"></i><span>全文约7.3K字</span></div><div class="pageview-post"><i class="icon fa-regular fa-eye"></i><span id="busuanzi_container_page_pv">阅读次数: <span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner"></i></span></span></div></div></div><div class="post-content"><blockquote>
<p>感觉今天去听华为的会呢，引发了我自己的一些思考。</p>
<p>发现我自己对待未来的规划还是做的太少，我应该更多的思考这方面的事情了。</p>
<p>比如，或许我的目标是在今年年底写完一篇论文，最好是构思好下一个工作要做什么，这样就可以按部就班的去做了。然后考虑明年或者今年年底可以实习。</p>
</blockquote>
<p> <strong>研究的目标：解决图片中不同类(不同菜品)的边界重叠/混合/覆盖的问题。</strong></p>
<p>目前的背景：（也就是存在的困境不止一个challenge）</p>
<ol>
<li>现在的场景(scenario)存在图片中不同类(不同菜品)的边界重叠/混合/覆盖的问题，导致对于中餐的识别/检测的准确度急速下降。</li>
<li>目前没人做中餐分割数据集（都不是数据集少的问题），是根本没人做。有关于中餐的复杂场景的数据集。</li>
<li>在复杂的菜品环境下，这样的数据被收集的很少。</li>
</ol>
<p>我个人感觉这个逻辑上还是存在问题，怎么样可以把逻辑组合的顺畅一点？</p>
<h2 id="背景：中餐词条"><a href="#背景：中餐词条" class="headerlink" title="背景：中餐词条"></a>背景：中餐词条</h2><blockquote>
<p>对中餐的理解、其体系、其内容等。</p>
</blockquote>
<p>【来源于百度百科-中餐词条】</p>
<p>中餐食材是一个庞大体系，常用食材就有2000余种。食材分类主要有：按食材的原生性角度分类，按食材的商品性质分类，按食材的加工状况分类，按食材的烹饪运用分类，按食材的产业来源分类，按食材的化学介入分类，按食材的生物属性分类。</p>
<p><img src="https://raw.githubusercontent.com/SchwertLin/Pic/main/imgresize%2Cm_lfit%2Climit_1%2Ch_1080.png" alt="img"></p>
<p>中餐工艺又称中餐加工工艺，由<strong>碎解工艺</strong>（刀法）、<strong>烹饪工艺</strong>、<strong>发酵工艺</strong>组成。中餐诞生以来，始终没有离开过这三种加工模式，它们包括了中餐所有的加工内容。</p>
<h3 id="碎解工艺"><a href="#碎解工艺" class="headerlink" title="碎解工艺"></a>碎解工艺</h3><p>通过物理的方法对食物进行加工。食材进入厨房后的物理性加工包括清理工作和食材切配两方面。</p>
<ul>
<li>清理技法：食材清理工艺分为食材的清洁方法、食材的解冻方法、食材的涨发方法、食材的分割方法。</li>
<li>刀工技法：分为直刀法、平刀法、斜刀法、剂刀法和其他刀法五种类型。</li>
<li>碎解形制：根据成菜要求，运用不同刀法，将食材加工成块、片、条、丝、丁、粒、末、泥、段等应用食材。</li>
<li>碎解组拼：冷拼技法有排、堆、叠、围、摆、覆、扎、瓤、包、塑、穿、串、酿、贴、扣、填等；依据食材类型，生食技法分为水果生食技法、蔬菜生食技法和动物生食技法。</li>
</ul>
<h3 id="烹饪工艺"><a href="#烹饪工艺" class="headerlink" title="烹饪工艺"></a>烹饪工艺</h3><p>通过热传导对食物进行加工，也是中餐加工中最重要的一种工艺模式。烹饪预熟工艺包括焯水、过油、汽蒸、走红、挂糊、上浆、烹前调味、烹前发酵等工艺环节。对于烹饪技法体系，迄今“有名有姓”、全国通用的技法就有四十余种，地方性的技法、不见于经传的技法更多。 从烹饪技法的科学原理入手，搭建了<strong>中餐烹饪7-3技术体系</strong>。“7”是“6+1”结构。6指依据传热介质的不同，将其分为烤、煮、蒸、炸、炒、复合6个烹饪技法类型。1指无热技法。“3”指中餐技法的三个层级。</p>
<p><img src="https://raw.githubusercontent.com/SchwertLin/Pic/main/imgimage-20251013141433628.png" alt="image-20251013141433628"></p>
<h3 id="发酵工艺"><a href="#发酵工艺" class="headerlink" title="发酵工艺"></a>发酵工艺</h3><p>利用微生物改变食物的性状。发酵工艺体系有三个层级，第一层级为菌种层级；第二层级依据各菌种下的生物类别划分，称为生类层级；第三层级为成品层级。中餐发酵二级技法体系见图：</p>
<p><img src="https://raw.githubusercontent.com/SchwertLin/Pic/main/imgimage-20251013141442720.png" alt="image-20251013141442720"></p>
<h2 id="背景：目前面临的挑战"><a href="#背景：目前面临的挑战" class="headerlink" title="背景：目前面临的挑战"></a>背景：目前面临的挑战</h2><h3 id="数据收集上"><a href="#数据收集上" class="headerlink" title="数据收集上"></a>数据收集上</h3><p>中餐以多种烹饪方式、多种食材进行加工而出名。</p>
<p>一是有关于中餐图片的数据集比较少；比如分类数据集，分类数据集只能够将整张图片作为一个整体去识别出一个类/菜品。此外，其粒度太粗，基本上是对于菜品整体进行识别，但是一到菜品中存在不同的食材。甚至说会有有不同的食材，但是被算作同一道菜的情况。这导致了类内差异大。</p>
<p>目前已有的有关于中餐的数据集有：ChinaFoodNet，Food2k等。</p>
<blockquote>
<p><em>比如，宫保鸡丁，可以是黄瓜+鸡丁，也可以是花生+鸡丁，有时也会有辣椒等。</em></p>
<p>WIKI百科上说：宫保鸡丁是<strong>中国四川、山东、贵州和北京的传统名菜，以鸡肉为主料，搭配花生米、辣椒等辅料经急火快炒制成，具有糊辣荔枝味型特征，红而不辣、肉质滑脆</strong>。 该菜起源于鲁菜酱爆鸡丁与贵州胡辣子鸡丁，由清朝山东巡抚丁宝桢改良推广形成新菜式，其名源自丁宝桢被追赠的“太子太保”官衔，并被归纳为北京宫廷菜。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th><img src="https://raw.githubusercontent.com/SchwertLin/Pic/main/imgb7b1d8b2b45b41a4b4c98b18cddc1b51.jpeg" alt="" style="zoom: 30%;" />黄瓜，胡萝不，花生，鸡丁</th>
<th><img src="https://raw.githubusercontent.com/SchwertLin/Pic/main/img600_600_webapp.jpg" alt="" style="zoom:50%;" />辣椒，花生，鸡丁，葱</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
</tr>
</tbody>
</table>
</div>
</blockquote>
<p>比如，目标检测数据集FoodDet100k。虽然可以在一张图片中识别出多道菜品，但是其粗粒度地只能识别出这是什么菜品，还是无法处理其食材种类。也存在上述的问题。</p>
<p>至于分割数据集，目前有有简单的FoodSeg103，一共有103种食材，是食材级别的分割。但是这个是西餐为主的数据集。<strong>综上，目前缺乏中餐、分割、多道菜品、食材级别的数据集。</strong></p>
<h3 id="现有方法上"><a href="#现有方法上" class="headerlink" title="现有方法上"></a>现有方法上</h3><blockquote>
<p>因为我们的场景是对于粘连的菜品（不同类别）进行识别，因此需要勾勒出其边界，因此我们将从分割任务的方法上进行调研。</p>
<p><em>（稍微感觉这一句话不知道在哪里提出会比较好）</em></p>
</blockquote>
<p>这就引出了第二个挑战。由于数据集导致的现有方法都不太准确。分为通用方法和专门方法。通用方法基于其他通用数据集设计，导致其泛化到食品上这种复杂情况下，准确度不高，mIoU在10-20左右。比如MaskFormer，OneFormer、MaskCLIP等。（我觉得选取对比方法上需要有自己的一个考量）</p>
<p>但是目前专门设计用来处理菜品的方法，OvsegFood的方法是闭源的，而且其目前达到的mIoU也是30左右。但是这个方法是在FoodSeg103上处理的，在中餐上的效果还是不好。那么有关于被设计用来专门处理中餐的复杂情况的分割方法就是<strong>没有</strong>。</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>那么基于上述的两个方面的研究空白，我们对此开展了研究。此研究的重点/重要之处在于：</p>
<ol>
<li>中餐在全球范围内有大部分的人以中餐为主要日常饮食摄入。通过对中餐进行评估，有助于我们可以对中餐中包含的营养物质进行研究、以及对于人体每日摄取对于人体健康的影响有更好的评估。</li>
</ol>
<h3 id="一些自己的思考"><a href="#一些自己的思考" class="headerlink" title="一些自己的思考"></a>一些自己的思考</h3><p>能不能基于决策树？决策树的优势是 “可解释性强、处理离散标签高效”</p>
<p>在最后预测cls的时候输出的vec可以是是一个多位数，每一个bit都包含一定的信息。这样可以压缩最后分类的维度。</p>
<blockquote>
<p>负采样 减少负标签冗余计算，或许可以化用。因为使用二进制的cls，导致label的稀疏性变得更大。或在标注时对高频维度（如食材）标注更密集，低频维度（如切割方式）用 “弱标注”（如仅标注关键区域），减少冗余。</p>
</blockquote>
<p>相当于我们现在也是具有两种模态信息，也就是文本和图像。但是问题在于，现在有关于多模态的方法可以被分为encoder-only和encoder-decoder的方法。</p>
<p>现在还有一个问题就是我们收集的图片数据是从网上扒的，也是包含很多的noise的。目前的研究比较倾向于img对应的text是alt text，其中包含很多的noise的信息。（FLIP生成文本较好）</p>
<blockquote>
<ol>
<li><p><strong>alt text 噪声处理可分 “预处理 - 训练 - 后处理” 三阶段</strong></p>
<p>论文的数据集无噪声（人工标注），但你的数据来自网络，可借鉴 “领域规则 + 模型筛选” 的思路：①预处理：用正则表达式过滤无意义文本（如 “图片 123”），保留含食品关键词的文本（如 “食材”“烹饪”“做法”）；②训练：用 “对比学习” 筛选高质量样本（如将图像与 alt text 输入 CLIP，相似度 &gt; 0.5 的样本用于训练，否则丢弃）；③后处理：对预测结果进行 “语义一致性检查”（如 “清蒸鱼” 的文本描述中不应出现 “油炸”，若出现则修正为 “蒸鱼”），类似论文 “负采样确保标签一致性”。</p>
</li>
<li><p><strong>hard negative 挖掘需结合 “食品领域语义” 设计</strong></p>
<p>论文无 hard negative 设计，但你的任务需区分相似食材，可参考 “领域内语义差异” 生成 hard negative：①食材层面：对 “鸡胸肉” 样本，将 “鸭胸肉”“火鸡胸肉” 作为 hard negative（而非 “土豆” 这种易区分的负样本）；②烹饪方式层面：对 “水煮” 样本，将 “清蒸” 作为 hard negative（二者质地相似）；③文本层面：对 alt text “番茄炒蛋”，生成 “番茄炒鸡蛋”（相似表述）、“番茄蛋汤”（烹饪方式差异）作为 hard negative。通过 “hard negative 对比损失”（如将样本 - 正文本的相似度与样本 - hard negative 文本的相似度差值最大化），提升 CLIP 对细粒度语义的区分能力，弥补其 “浅层相似度” 的不足。</p>
</li>
</ol>
</blockquote>
<p>再一个，我不看好clip在我的任务中得到比较好的结果，因为clip是提取的img-text的非常shallow的similarity，对于我们图片中属于一个大的食品空间下的十分多非常相似的食材来看，他们的相似度应该非常的高，所以需要一个hard negative，然后再找找看看有什么策略可以比较好处理noise。</p>
<p>在损失函数的设计上，一种想法是针对我们这个特定的领域去施加正则化约束/也就是添加适应的loss function。另外一种想法是做通用的loss，而不需要很多的loss，因为“简单就是最强的”。</p>
<blockquote>
<p>BCE loss（交叉熵损失）-分割分类，类似ITM（img-text matching）但是不太一样，这个是与GT计算，ITM是计算img-text是不是匹配的，都可以要。</p>
<p>ICT loss（对比学习损失）-img-text的匹配，（如 “番茄块” 区域与 “番茄” 文本的相似度最大化，与 “土豆” 文本的相似度最小化）</p>
<p>MLM（Mask language matching loss）-文本进行完形填空（或许img也可以？）</p>
</blockquote>
<p>我认为或许可以结合这两种？就是设计一个通用于Food领域的loss，保证在Food领域具有很强的通用性。但是其实做通用loss的原因之一是因为：反复算很多的loss，有的输入不一样，会导致做多次的feedforward前馈过程，会加剧计算量/时间消耗。</p>
<blockquote>
<p><strong>食品领域约束：添加轻量化正则化项</strong></p>
<p>在通用 loss 基础上，添加 1-2 个食品领域专属正则化项，而非多个复杂 loss，平衡性能与效率：①“食材 - 烹饪方式一致性约束”：若标签为 “油炸鸡翅”，则 “鸡翅” 区域的 “油炸” 语义概率需高于 “清蒸”（通过 L1 损失强制二者差值 &gt; 0.3），避免出现 “清蒸鸡翅标注为油炸” 的矛盾；</p>
<p>②“切割方式 - 区域形态约束”：若标签为 “切丁胡萝卜”，则胡萝卜区域的外接矩形长宽比需接近 1（通过形态学特征与语义概率的相关性损失优化），类似论文 “负采样约束标签稀疏性” 的思路，用领域知识引导模型学习关键语义关联。这种设计既保留了通用 loss 的简洁性，又通过轻量化约束提升了食品领域的适配性，避免 “为了精度添加过多 loss 导致计算量失控”。</p>
</blockquote>
<p>总的来说，目前的挑战可以再丰富一点：还是分为数据上的和方法上的。上面的都可以归结进去。</p>
<blockquote>
<p>下面是豆包总结的，但只是对前面的进行总结，实际上也不是很fit</p>
<h3 id="（一）数据层面挑战"><a href="#（一）数据层面挑战" class="headerlink" title="（一）数据层面挑战"></a>（一）数据层面挑战</h3><ol>
<li><strong>噪声数据的 “质量 - 数量” 平衡</strong>：网上爬取的图像 /alt text 存在 “文本与图像不匹配”（如 “红烧肉图片配番茄炒蛋文本”）、“语义模糊”（如仅标注 “家常菜”）问题，需设计高效的清洗策略（如 CLIP 相似度筛选、决策树规则纠错），避免噪声影响模型训练；同时，需保证清洗后的数据量足够支撑多维度语义学习（如每种烹饪方式至少 1000 个样本）。</li>
<li><strong>标签的 “细粒度 - 标注成本” 矛盾</strong>：需标注 “菜品 + 食材 + 烹饪方式 + 切割方式” 等多维信息，像素级标注成本极高，如何借鉴论文 “图像级标注降低成本” 的思路，设计 “弱标注 + 自动补全” 方案（如先标注图像级菜品类别，再通过模型预测补全像素级食材标签），平衡标注精度与效率。</li>
<li><strong>相似食材的 “数据稀缺性”</strong>：如 “鸡胸肉” vs “鸭胸肉”“普通番茄” vs “圣女果” 等细粒度类别，网上数据量少且易混淆，需人工扩充数据（如拍摄专业样本）或通过数据增强（如调整色泽、添加纹理）生成相似样本，避免模型对小众食材的漏识别。</li>
</ol>
<h3 id="（二）方法层面挑战"><a href="#（二）方法层面挑战" class="headerlink" title="（二）方法层面挑战"></a>（二）方法层面挑战</h3><ol>
<li><strong>CLIP 的 “浅层相似度” 与 “细粒度语义” 的适配</strong>：CLIP 难以区分食品领域的相似语义（如 “切丝” vs “切末”“油炸” vs “油煎”），需设计 “领域微调 + hard negative 对比学习” 方案，提升跨模态匹配的细粒度，同时避免微调导致的过拟合（如用少量高质量数据微调）。</li>
<li><strong>多维度语义的 “特征关联与冲突解决”</strong>：不同语义维度可能存在关联（如 “油炸”→“小块食材”）或冲突（如 “大块食材” 标注为 “切丝”），如何通过 “特征融合（多尺度 CLIP 特征）+ 领域约束损失（语义一致性）” 让模型学习合理的语义关联，避免维度间的相互干扰。</li>
<li><strong>“效率 - 精度” 的平衡</strong>：多模态、多尺度、多 loss 的组合易导致计算量激增（如 encoder-decoder 的多次前馈、hard negative 的额外计算），需优化架构（如轻量化 CLIP 模型、多 loss 共享特征提取层），在保证分割精度的同时，满足实际应用的实时性需求（如推理速度 &gt; 10fps）。</li>
</ol>
</blockquote>
<h2 id="一些与GPT交流的内容"><a href="#一些与GPT交流的内容" class="headerlink" title="一些与GPT交流的内容"></a>一些与GPT交流的内容</h2><blockquote>
<ol>
<li><p>你计划将该研究聚焦于图像分割（semantic/instance/panoptic segmentation）中的哪一类任务？是以菜品为类，还是以食材为类？我将聚焦于语义分割，想要通过以菜品级分割+食材级属性额外信息 来识别到图片中哪些区域属于什么菜，这个菜中包含什么食材。通过额外的信息，我们后续可以去开展一些下游工作，比如中餐的营养评估或VQA等。</p>
</li>
<li><p>你是否计划构建一个新的中餐分割数据集，还是使用已有数据（比如从FoodDet100k或ChinaFoodNet中抽取）？是的，我们现在已经收集了10k的混合菜品的数据图片，但是目前在标注分割的mask中。你或许可以指导一下我的数据集要怎么继续标注、以及我现在的数量级是不是太小了，如果我想要提高方法的效率，我应该将数据集扩大到多大是比较合理且efficient的？有什么流程或者是理论上可以支撑？</p>
</li>
<li><p>你是否已有一些初步的方案（比如数据增强、图像生成、边界建模、跨模态等）或希望调研的方法方向？是的，因为我们要标注的类别非常的多、但是类别对应的图片/数据又很少。我现在的想法是：在数据上，对现有数据进行数据增强来增加数据量。考虑能不能以少量的精确标注（比如额外信息标注出一个菜品中包含什么食材、都是以什么方式被处理的、包含什么佐料等），能够泛化到更大的范围进行识别。在方法上，考虑机遇CLIP来结合文本数据和图像数据去设计自己的方法，然后可能采用MoE的架构，强化学习的方法来进行优化等等。</p>
</li>
<li><p>是否有特定应用场景，比如餐盘估算、卡路里识别、智能食堂等？是的，目前先针对的特定的场景是想要落地的应用：比如给出一个餐盘，我需要准确的识别出来这里都有什么菜（原来是因为菜品粘连导致识别的准确度不高），这样可以帮助在食堂或餐厅中能够智能计算价格之类（以菜品不同来收钱）。后续可能会扩展下游任务，比如进行卡路里识别、营养评估等。</p>
</li>
</ol>
</blockquote>
<h3 id="经过GPT完善的研究背景与挑战"><a href="#经过GPT完善的研究背景与挑战" class="headerlink" title="经过GPT完善的研究背景与挑战"></a>经过GPT完善的研究背景与挑战</h3><p>在图像分割领域，中餐菜品具有独特挑战。</p>
<ul>
<li>一方面，中餐菜品种类繁多、制作方法复杂，同一道菜在不同地区和做法下可能包含截然不同的食材和配料。已有研究指出，“单个食品的外观可能因不同加工方式而存在极大差异，这在复杂菜系（如中国菜）中尤为明显”<a target="_blank" rel="noopener" href="https://www.mdpi.com/2304-8158/14/17/3016#:~:text=However%2C food image segmentation is,numerous small%2C individual components%2C exemplifies">mdpi.com</a>。（例子：宫保鸡丁）</li>
<li>另一方面，多道菜品常在同一餐盘上出现且相互重叠，菜品之间的边界常常不清晰。例如，混合菜识别任务的研究就提到：“同一餐盘上的不同菜肴可能相互重叠，且它们之间可能没有明确的边界”<a target="_blank" rel="noopener" href="https://openreview.net/forum?id=2UdPebY01j#:~:text=Abstract%3A Mix dish recognition%2C whose,mixed economic rice and economic">openreview.net</a>。这样的重叠和边界模糊会大幅降低现有识别/检测方法的准确率。</li>
</ul>
<p>简而言之，多道中餐图像分割面临着<strong>类内差异大、类间重叠边界模糊</strong>等问题，亟需针对性的数据集和方法研究。</p>
<p>当前相关研究主要集中在单道西餐的分割或中餐的分类与检测，但几乎没有专门针对多道中餐分割（即在一张图像中同时对多道不同中餐进行区域划分）的公开数据集。</p>
<ul>
<li>一方面，<strong>数据集不足</strong>：例如，中国菜分类数据集“ChineseFoodNet”包含18万张图像、208类<a target="_blank" rel="noopener" href="https://ar5iv.labs.arxiv.org/html/1705.02743#:~:text=1">ar5iv.labs.arxiv.org</a>；FoodDet100k等目标检测数据集能标注出一张图中多个菜名，但仅提供粗粒度的菜品框选标签，无法细致地勾勒出各菜品的区域和内部成分。现有以食材为分割对象的数据集如FoodSeg103（包含7118张图像、103种西餐食材的像素级标注）<a target="_blank" rel="noopener" href="https://huggingface.co/datasets/EduardoPacheco/FoodSeg103#:~:text=FoodSeg103 is a large,contains 4983 images and the">huggingface.co</a>，主要面向西餐环境，且图片通常只有单一道菜。因此目前<strong>缺乏一个多道中餐场景的、食材级别或菜品级别的分割数据集</strong>。</li>
<li>另一方面，<strong>算法方法局限</strong>：通用分割方法（如MaskFormer、OneFormer、MaskCLIP等）多基于通用场景数据训练，迁移到复杂的中餐场景时往往性能不佳。例如在FoodSeg103等公开数据集上，MaskCLIP的mIoU仅约为33%<a target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content/CVPR2024/papers/Wu_OVFoodSeg_Elevating_Open-Vocabulary_Food_Image_Segmentation_via_Image-Informed_Textual_Representation_CVPR_2024_paper.pdf#:~:text=mIoUn mIoUb mIoUo mIoUn mIoUb,7">openaccess.thecvf.com</a>。尽管有针对食物分割的研究（如最新的OVFoodSeg在FoodSeg103上表现略有提升），但这些方法主要面向食材分割，且目前专门处理中餐复杂情况的公开方法并不存在。</li>
</ul>
<p><strong>综上所述，现有的数据和方法都难以应对多道中餐的重叠混合问题</strong>，这就引出了我们研究的必要性。</p>
<h3 id="经过GPT完善的研究任务与目标"><a href="#经过GPT完善的研究任务与目标" class="headerlink" title="经过GPT完善的研究任务与目标"></a>经过GPT完善的研究任务与目标</h3><p>针对上述挑战，我们计划聚焦于<strong>语义分割</strong>任务。具体而言，我们将把每种菜品作为一个语义类别，对单张图像中的各区域进行分类，进而确定哪些像素属于哪道菜。</p>
<blockquote>
<p>这一段相当于在解释，食品分割中的语义分割的含义。</p>
</blockquote>
<p>此外，我们还计划引入<strong>菜品的属性信息</strong>（如所含食材类型）作为辅助。通过先做菜品级语义分割并识别出不同菜品区域，然后结合识别出的菜名或额外标签，进一步推断该菜品包含哪些食材。</p>
<blockquote>
<p>这一段比较空泛，不够细致。</p>
</blockquote>
<p>这样的方法有助于下游任务，如营养评估或视觉问答等。<strong>例如，已有研究表明</strong>，精确的食物图像分割对于自动化饮食记录、营养成分分析具有重要意义<a target="_blank" rel="noopener" href="https://www.mdpi.com/2304-8158/14/17/3016#:~:text=Precisely identifying and delineating food,grained">mdpi.com</a>。在我们的应用场景中，分割结果可用于智能食堂结算——准确勾勒出各菜品区域后，可精确统计每种菜品的数量并估价；后续也可用于卡路里计算和营养分析。</p>
<blockquote>
<p>这一段相当于是研究意义。当然，作为研究意义的话还需要补充：就是这个补充了/弥补了目前在中餐分割上研究的空白。我认为有研究能够证明这个研究确实对于营养评估是有用的，这个还是蛮有必要的。</p>
</blockquote>
<p>需要注意的是，虽然语义分割将每道菜视为一个类别进行像素级划分，但在多盘同一道菜同时出现的情况下，或者需要区分同一类菜的不同实例时，实例分割或全景分割也值得考虑。实例分割能够区分相同类别的不同实例，全景分割则整合了语义和实例信息。但鉴于目前我们关注的是“画出不同菜品的边界”，且目标是先识别菜品种类，我们将首先采用语义分割，并在有需要时结合实例分割策略（如必要时应用带类别标签的Mask R-CNN等）作为补充。</p>
<h3 id="技术路线"><a href="#技术路线" class="headerlink" title="技术路线"></a>技术路线</h3><p>我们可以从多模态融合（借助菜品文本信息）、网络结构创新（MoE、边缘增强）、训练策略（多任务、迁移学习）等方面协同发力，以应对类别多样、样本有限且边界模糊的挑战。在早期实验中，我们会对比纯视觉分割模型和引入文本食材信息的模型，以评估后者在菜品-食材关联上的效果。</p>
<ul>
<li><p><strong>多模态信息融合</strong>：借助文本-图像模型（如CLIP）将视觉特征与菜品名称或食材信息关联。比如，可以为每种菜品构造描述（“宫保鸡丁包含鸡肉、花生、辣椒”等），利用CLIP提取图像和文本的共同嵌入空间，从而帮助分割模型更好地区分视觉相似的菜品。这类似于<strong>开放词汇分割</strong>（open-vocabulary segmentation）的思路，已有方法（如OVFoodSeg）通过图像指导的文本嵌入提升分割性能<a target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content/CVPR2024/papers/Wu_OVFoodSeg_Elevating_Open-Vocabulary_Food_Image_Segmentation_via_Image-Informed_Textual_Representation_CVPR_2024_paper.pdf#:~:text=MaskCLIP ,7">openaccess.thecvf.com</a>。我们也可借鉴其架构，将图像特征注入到文本编码器中，生成食材或菜名的图像感知文本嵌入，用于指导分割。</p>
</li>
<li><p><strong>模型架构设计</strong>：在网络架构上，可探索<strong>混合专家（MoE）</strong>或模块化设计：针对不同菜系或菜品特点设计专门的网络分支（专家），再通过路由机制选择合适专家来处理输入。这有助于模型应对菜品多样性。</p>
<p>也可以尝试<strong>层级分支</strong>，先分割出所有菜品区域（大类别），再对每个区域做细分类或细分食材掩码。另一种思路是结合<strong>边缘感知网络</strong>（如MVEANet<a target="_blank" rel="noopener" href="https://www.mdpi.com/2304-8158/14/17/3016#:~:text=overcome these challenges%2C we proposed,well in depicting clear and">mdpi.com</a>）强化对边界的捕捉能力，以更精细地勾勒粘连菜品的轮廓。</p>
</li>
<li><p><strong>训练策略</strong>：对于多类极不平衡的数据，<strong>强化学习（RL）\</strong>可以用于优化样本选择或数据增强策略，例如用RL来学习最佳的增强组合或负样本挖掘策略，从而提升训练效率。但RL直接用于分割优化较为少见，需要谨慎考虑应用场景。更实际的做法是结合*<em>多任务学习*</em>：联合训练分割和食材/菜名分类任务，通过共享特征和互相约束，提高整体性能。</p>
</li>
<li><p><strong>其他技术</strong>：考虑到同类食材形态多变，我们也可以尝试<strong>迁移学习</strong>与<strong>自监督预训练</strong>。如先在大规模通用图像或食物图片上预训练（参考Wu等人提出的ReLeM模型对食物进行预训练<a target="_blank" rel="noopener" href="https://www.mdpi.com/2304-8158/14/17/3016#:~:text=Furthermore%2C dedicated efforts in food,applications in food image segmentation">mdpi.com</a>），再微调到我们的中餐分割任务上。此外，使用<strong>密集监督</strong>如边界损失（dice loss、IoU loss等）来对重叠边缘进行正则化，也常见于分割任务<a target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content/CVPR2024/papers/Wu_OVFoodSeg_Elevating_Open-Vocabulary_Food_Image_Segmentation_via_Image-Informed_Textual_Representation_CVPR_2024_paper.pdf#:~:text={E}_ %3D \text {CLIP,Entropy loss">openaccess.thecvf.com</a>。</p>
</li>
</ul>
<h3 id="应用前景或影响"><a href="#应用前景或影响" class="headerlink" title="应用前景或影响"></a>应用前景或影响</h3><p>研究多道中餐图像分割的意义不仅在算法上，更在于实际应用价值。精准分割出每道菜品区域有助于<strong>智能食堂</strong>或餐饮业场景：系统可以自动识别盘中有哪些菜、各自面积比例，进而实现按菜收费、菜品盘点等功能，减轻人工成本。同时，分割结果可用于<strong>营养和热量估计</strong>：结合食材识别结果和餐厅配餐数据库，可以计算每道菜的营养成分，从而辅助个人膳食记录和健康管理。有研究表明，食物分割是自动饮食记录和营养分析的基础<a target="_blank" rel="noopener" href="https://www.mdpi.com/2304-8158/14/17/3016#:~:text=Precisely identifying and delineating food,grained">mdpi.com</a>。因此，我们的工作可为进一步的卡路里计算、膳食评价乃至健康监测提供重要支撑，具有较高的社会效益。</p>
<h3 id="TFN"><a href="#TFN" class="headerlink" title="TFN"></a>TFN</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TFN</span>(nn.Module):    </span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, d_x, d_y, d_z, out_dim</span>):        </span><br><span class="line">    <span class="built_in">super</span>(TFN, <span class="variable language_">self</span>).__init__()        </span><br><span class="line">    <span class="variable language_">self</span>.d_x, <span class="variable language_">self</span>.d_y, <span class="variable language_">self</span>.d_z = d_x, d_y, d_z <span class="comment"># 计算融合后特征维度（加1为偏置项）       </span></span><br><span class="line">    fusion_dim = (d_x + <span class="number">1</span>) * (d_y + <span class="number">1</span>) * (d_z + <span class="number">1</span>)        </span><br><span class="line">    <span class="variable language_">self</span>.fc = nn.Linear(fusion_dim, out_dim)  <span class="comment"># 展平后映射到输出维度    </span></span><br><span class="line">  </span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, y, z</span>):</span><br><span class="line">    <span class="comment"># 给每个特征加偏置项1（batch_size维度保持不变） </span></span><br><span class="line">    x_with_bias = torch.cat([x, torch.ones_like(x[:, :<span class="number">1</span>])], dim=<span class="number">1</span>)  <span class="comment"># (bs, d_x+1)     </span></span><br><span class="line">    y_with_bias = torch.cat([y, torch.ones_like(y[:, :<span class="number">1</span>])], dim=<span class="number">1</span>)  <span class="comment"># (bs, d_y+1)     </span></span><br><span class="line">    z_with_bias = torch.cat([z, torch.ones_like(z[:, :<span class="number">1</span>])], dim=<span class="number">1</span>)  <span class="comment"># (bs, d_z+1)    </span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 张量外积：先计算x与y的外积，再与z做外积        </span></span><br><span class="line">    xy = torch.einsum(<span class="string">&#x27;bi,bj-&gt;bij&#x27;</span>, x_with_bias, y_with_bias)  <span class="comment"># (bs, d_x+1, d_y+1)  </span></span><br><span class="line">    xyz = torch.einsum(<span class="string">&#x27;bij,bk-&gt;bijk&#x27;</span>, xy, z_with_bias) <span class="comment"># (bs, d_x+1, d_y+1, d_z+1)  </span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 展平为向量        </span></span><br><span class="line">    xyz_flat = xyz.view(xyz.shape[<span class="number">0</span>], -<span class="number">1</span>)  <span class="comment"># (bs, (d_x+1)(d_y+1)(d_z+1))</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 输出融合结果</span></span><br><span class="line">    <span class="keyword">return</span> <span class="variable language_">self</span>.fc(xyz_flat)  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 测试</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:    </span><br><span class="line">  bs = <span class="number">32</span>  <span class="comment"># batch_size    </span></span><br><span class="line">  d_x, d_y, d_z = <span class="number">50</span>, <span class="number">64</span>, <span class="number">32</span>  <span class="comment"># 文本、图像、语音特征维度    </span></span><br><span class="line">  x = torch.randn(bs, d_x)    </span><br><span class="line">  y = torch.randn(bs, d_y)    </span><br><span class="line">  z = torch.randn(bs, d_z)        </span><br><span class="line">  model = TFN(d_x, d_y, d_z, out_dim=<span class="number">10</span>)  <span class="comment"># 输出维度10（如10分类）    </span></span><br><span class="line">  out = model(x, y, z)    </span><br><span class="line">  <span class="built_in">print</span>(<span class="string">&quot;TFN输出形状:&quot;</span>, out.shape)  <span class="comment"># 应输出 (32, 10)</span></span><br></pre></td></tr></table></figure>
<h3 id="LMF"><a href="#LMF" class="headerlink" title="LMF"></a>LMF</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 核心思路：拆解为“模态线性变换 + 低秩交叉”</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LMF</span>(nn.Module):    </span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, d_a, d_v, d_l, K, out_dim</span>):        </span><br><span class="line">    <span class="built_in">super</span>(LMF, <span class="variable language_">self</span>).__init__()        </span><br><span class="line">    <span class="variable language_">self</span>.K = K  <span class="comment"># 低秩维度        </span></span><br><span class="line">    <span class="comment"># 各模态线性变换（映射到K个低秩分量）        </span></span><br><span class="line">    <span class="variable language_">self</span>.fc_a = nn.Linear(d_a, K)        </span><br><span class="line">    <span class="variable language_">self</span>.fc_v = nn.Linear(d_v, K)        </span><br><span class="line">    <span class="variable language_">self</span>.fc_l = nn.Linear(d_l, K)        </span><br><span class="line">    <span class="comment"># 最终输出层        </span></span><br><span class="line">    <span class="variable language_">self</span>.fc_out = nn.Linear(K, out_dim)    </span><br><span class="line"> 	<span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x_a, x_v, x_l</span>):        </span><br><span class="line">    <span class="comment"># 各模态映射到低秩空间        </span></span><br><span class="line">    z_a = <span class="variable language_">self</span>.fc_a(x_a).unsqueeze(-<span class="number">1</span>)  <span class="comment"># (bs, K, 1)        </span></span><br><span class="line">    z_v = <span class="variable language_">self</span>.fc_v(x_v).unsqueeze(-<span class="number">1</span>)  <span class="comment"># (bs, K, 1)        </span></span><br><span class="line">    z_l = <span class="variable language_">self</span>.fc_l(x_l).unsqueeze(-<span class="number">1</span>)  <span class="comment"># (bs, K, 1)        </span></span><br><span class="line">    <span class="comment"># 低秩交叉：元素积求和（K个分量分别交叉后相加）        </span></span><br><span class="line">    fusion = (z_a * z_v * z_l).<span class="built_in">sum</span>(dim=-<span class="number">1</span>)  <span class="comment"># (bs, K)        </span></span><br><span class="line">    <span class="keyword">return</span> <span class="variable language_">self</span>.fc_out(fusion)  <span class="comment"># (bs, out_dim)</span></span><br></pre></td></tr></table></figure>
</div><div class="post-end"><div class="post-prev"><a href="/2025/10/13/2025-10-13/" title="上一篇文章"><i class="fa-solid fa-chevron-left fa-lg"></i></a></div><div class="post-next"><a href="/2025/10/10/2025-10-10/" title="下一篇文章"><i class="fa-solid fa-chevron-right fa-lg"></i></a></div></div></article><div class="comment" id="comment"><script src="https://giscus.app/client.js" data-repo="SchwertLin/SwertLin_Blog_Comment" data-repo-id="R_kgDONXjrCQ" data-category="Announcements" data-category-id="DIC_kwDONXjrCc4Cky9X" data-mapping="pathname" data-strict="0" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="bottom" data-theme="preferred_color_scheme" data-lang="zh-CN" crossorigin="anonymous" async="async"></script></div><div id="post-toc"><aside class="toc-aside"><div class="toc-title"><span><i class="fa-solid fa-paw"></i>目录</span></div><div class="toc-container" id="toc-body"><ol class="toc-content"><li class="toc-content-item toc-content-level-2"><a class="toc-content-link" href="#%E8%83%8C%E6%99%AF%EF%BC%9A%E4%B8%AD%E9%A4%90%E8%AF%8D%E6%9D%A1"><span class="toc-content-number">1.</span> <span class="toc-content-text">背景：中餐词条</span></a><ol class="toc-content-child"><li class="toc-content-item toc-content-level-3"><a class="toc-content-link" href="#%E7%A2%8E%E8%A7%A3%E5%B7%A5%E8%89%BA"><span class="toc-content-number">1.1.</span> <span class="toc-content-text">碎解工艺</span></a></li><li class="toc-content-item toc-content-level-3"><a class="toc-content-link" href="#%E7%83%B9%E9%A5%AA%E5%B7%A5%E8%89%BA"><span class="toc-content-number">1.2.</span> <span class="toc-content-text">烹饪工艺</span></a></li><li class="toc-content-item toc-content-level-3"><a class="toc-content-link" href="#%E5%8F%91%E9%85%B5%E5%B7%A5%E8%89%BA"><span class="toc-content-number">1.3.</span> <span class="toc-content-text">发酵工艺</span></a></li></ol></li><li class="toc-content-item toc-content-level-2"><a class="toc-content-link" href="#%E8%83%8C%E6%99%AF%EF%BC%9A%E7%9B%AE%E5%89%8D%E9%9D%A2%E4%B8%B4%E7%9A%84%E6%8C%91%E6%88%98"><span class="toc-content-number">2.</span> <span class="toc-content-text">背景：目前面临的挑战</span></a><ol class="toc-content-child"><li class="toc-content-item toc-content-level-3"><a class="toc-content-link" href="#%E6%95%B0%E6%8D%AE%E6%94%B6%E9%9B%86%E4%B8%8A"><span class="toc-content-number">2.1.</span> <span class="toc-content-text">数据收集上</span></a></li><li class="toc-content-item toc-content-level-3"><a class="toc-content-link" href="#%E7%8E%B0%E6%9C%89%E6%96%B9%E6%B3%95%E4%B8%8A"><span class="toc-content-number">2.2.</span> <span class="toc-content-text">现有方法上</span></a></li><li class="toc-content-item toc-content-level-3"><a class="toc-content-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-content-number">2.3.</span> <span class="toc-content-text">总结</span></a></li><li class="toc-content-item toc-content-level-3"><a class="toc-content-link" href="#%E4%B8%80%E4%BA%9B%E8%87%AA%E5%B7%B1%E7%9A%84%E6%80%9D%E8%80%83"><span class="toc-content-number">2.4.</span> <span class="toc-content-text">一些自己的思考</span></a></li><li class="toc-content-item toc-content-level-3"><a class="toc-content-link" href="#%EF%BC%88%E4%B8%80%EF%BC%89%E6%95%B0%E6%8D%AE%E5%B1%82%E9%9D%A2%E6%8C%91%E6%88%98"><span class="toc-content-number">2.5.</span> <span class="toc-content-text">（一）数据层面挑战</span></a></li><li class="toc-content-item toc-content-level-3"><a class="toc-content-link" href="#%EF%BC%88%E4%BA%8C%EF%BC%89%E6%96%B9%E6%B3%95%E5%B1%82%E9%9D%A2%E6%8C%91%E6%88%98"><span class="toc-content-number">2.6.</span> <span class="toc-content-text">（二）方法层面挑战</span></a></li></ol></li><li class="toc-content-item toc-content-level-2"><a class="toc-content-link" href="#%E4%B8%80%E4%BA%9B%E4%B8%8EGPT%E4%BA%A4%E6%B5%81%E7%9A%84%E5%86%85%E5%AE%B9"><span class="toc-content-number">3.</span> <span class="toc-content-text">一些与GPT交流的内容</span></a><ol class="toc-content-child"><li class="toc-content-item toc-content-level-3"><a class="toc-content-link" href="#%E7%BB%8F%E8%BF%87GPT%E5%AE%8C%E5%96%84%E7%9A%84%E7%A0%94%E7%A9%B6%E8%83%8C%E6%99%AF%E4%B8%8E%E6%8C%91%E6%88%98"><span class="toc-content-number">3.1.</span> <span class="toc-content-text">经过GPT完善的研究背景与挑战</span></a></li><li class="toc-content-item toc-content-level-3"><a class="toc-content-link" href="#%E7%BB%8F%E8%BF%87GPT%E5%AE%8C%E5%96%84%E7%9A%84%E7%A0%94%E7%A9%B6%E4%BB%BB%E5%8A%A1%E4%B8%8E%E7%9B%AE%E6%A0%87"><span class="toc-content-number">3.2.</span> <span class="toc-content-text">经过GPT完善的研究任务与目标</span></a></li><li class="toc-content-item toc-content-level-3"><a class="toc-content-link" href="#%E6%8A%80%E6%9C%AF%E8%B7%AF%E7%BA%BF"><span class="toc-content-number">3.3.</span> <span class="toc-content-text">技术路线</span></a></li><li class="toc-content-item toc-content-level-3"><a class="toc-content-link" href="#%E5%BA%94%E7%94%A8%E5%89%8D%E6%99%AF%E6%88%96%E5%BD%B1%E5%93%8D"><span class="toc-content-number">3.4.</span> <span class="toc-content-text">应用前景或影响</span></a></li><li class="toc-content-item toc-content-level-3"><a class="toc-content-link" href="#TFN"><span class="toc-content-number">3.5.</span> <span class="toc-content-text">TFN</span></a></li><li class="toc-content-item toc-content-level-3"><a class="toc-content-link" href="#LMF"><span class="toc-content-number">3.6.</span> <span class="toc-content-text">LMF</span></a></li></ol></li></ol></div></aside><div class="toc-blank" onclick="tocToggle()"></div></div><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  }
});
MathJax.Hub.Queue(function() {
  var all = MathJax.Hub.getAllJax(), i;
  for(i=0; i < all.length; i += 1) {
    all[i].SourceElement().parentNode.className += ' has-jax';
  }
});
</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.8/MathJax.js?config=TeX-AMS-MML_HTMLorMML" async="async"></script></div></div><div id="tool-bar"><div id="tool-bar-main"><div id="tool-toggle" onclick="toolToggle()" title="设置"><i class="fa-solid fa-gear"></i></div><div id="toc-toggle" onclick="tocToggle()" title="目录"><i class="fa-solid fa-list-ul"></i></div><div id="go-to-comment" onclick="gotoComment()" title="评论"><i class="fa-regular fa-message fa-flip-horizontal"></i></div><div id="back-to-top" onclick="scrollToTop()" title="返回顶部"><i class="fa-solid fa-chevron-up"></i></div></div><div id="tool-bar-more" style="display: none;"><div id="darkmode-switch" onclick="darkmodeSwitch()" title="深色模式"><i class="fa-solid fa-circle-half-stroke"></i></div><div id="font-size-increase" onclick="fontSizeIncrease()" title="放大字体"><i class="fa-solid fa-plus"></i></div><div id="font-size-decrease" onclick="fontSizeDecrease()" title="缩小字体"><i class="fa-solid fa-minus"></i></div></div></div><div id="search-panel"><div class="search-container"><div class="search-head"><div class="search-title"><span><i class="fa-solid fa-paw"></i>搜索</span></div><div class="search-close-btn" onclick="toggleSearchWindow()"><i class="fa-regular fa-circle-xmark"></i></div></div><div class="search-box"><i class="fa-solid fa-magnifying-glass"></i><input id="search-input" type="text" placeholder="请输入需要搜索的内容……" value=""/></div><div class="search-body"><div id="search-count">匹配结果数: </div><div id="search-result"></div><div id="search-result-empty">未搜索到匹配的文章。</div></div></div></div><footer><div class="footer-content"><div class="copyright-info"><i class="fa-regular fa-copyright fa-xs"></i><span>2022 - 2026 </span><a href="/about">Schwertlilien</a><i class="fa-solid fa-cat fa-sm"></i><span>Powered by </span><a href="https://hexo.io/" target="_blank">Hexo</a><span> &amp; </span><a href="https://github.com/chanwj/hexo-theme-meow" target="_blank" title="v2.1.0">Theme Meow</a></div><div class="pageview-site"><span id="busuanzi_container_site_pv">总访问量 : <span id="busuanzi_value_site_pv"><i class="fa-solid fa-spinner"></i></span></span><span id="busuanzi_container_site_uv">总访客数 : <span id="busuanzi_value_site_uv"><i class="fa-solid fa-spinner"></i></span></span></div></div></footer>
<script>const GLOBAL_CONFIG = {
  comment: { theme: 'preferred_color_scheme'}
}
</script>
<script src="/js/third-party/darkmode.js"></script>
<script>var options = {
  dark: '/css/darkmode.css',
  startAt: '24:00',
  endAt: '06:00',
  checkSystemScheme: 'false',
  saveOnToggle: 'true'
};
var darkMode = new DarkMode(options);
// change comment theme synchronously 同步修改评论区主题
if (darkMode.getMode() == "dark" && (true || true)) {
  if (document.getElementById('comment')) {
    document.getElementById('comment').getElementsByTagName('script')[0].setAttribute('data-theme', 'noborder_dark');
  }
}
</script><script>if (localStorage.getItem('font-size')) {
  document.querySelector('.post-content').style.fontSize = localStorage.getItem('font-size') + 'px';
}
</script>
<script src="/js/theme/tool-bar.js"></script>


<script src="/js/theme/menu.js"></script>


<script src="/js/third-party/clipboard.min.js"></script>


<script src="/js/theme/copy.js"></script>
<script>copyCode();
</script>
<script src="/js/jquery-3.7.1.min.js"></script>


<script src="/js/theme/search.js"></script>
<script>searchFunc('/search.xml', 'search-input', 'search-result');
</script></body></html>